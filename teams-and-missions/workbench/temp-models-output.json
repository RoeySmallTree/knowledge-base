[
  {
    "id": 123,
    "vendor_id": 9,
    "api_id": "deepseek/deepseek-v3.2",
    "slug": "deepseek-v3.2",
    "display_name": "DeepSeek V3.2",
    "display_order": 10,
    "description": "Frontier open-source with integrated thinking",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 163840,
    "price_prompt_micro": 250000,
    "price_completion_micro": 380000,
    "price_tier": 1,
    "fallback_model_id": 126,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:14:58.628633+00:00",
    "parameter_count_b": 685,
    "personality_traits": [
      "Deep-Thinker",
      "Cost-Efficient"
    ],
    "professional_traits": [],
    "best_for": [
      "cost-sensitive enterprise"
    ],
    "active_parameter_count_b": 37,
    "creativity_score": 65,
    "logic_score": 90,
    "efficiency_score": 95,
    "model_family": "V3.2",
    "name_within_family": "V3.2"
  },
  {
    "id": 128,
    "vendor_id": 9,
    "api_id": "deepseek/deepseek-r1-0528",
    "slug": "deepseek-r1-0528",
    "display_name": "R1 0528",
    "display_order": 60,
    "description": "Major R1 upgrade - approaches o3 and Gemini 2.5 Pro",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 163840,
    "price_prompt_micro": 400000,
    "price_completion_micro": 1750000,
    "price_tier": 2,
    "fallback_model_id": 132,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:23:35.616513+00:00",
    "parameter_count_b": 671,
    "personality_traits": [
      "Deep-Thinker",
      "Math-Strong",
      "Open-Reasoning",
      "Self-Verifying"
    ],
    "professional_traits": [
      "Chain-of-thought reasoning",
      "web search"
    ],
    "best_for": [
      "Complex reasoning",
      "math",
      "coding",
      "research",
      "visible thought process"
    ],
    "active_parameter_count_b": 37,
    "creativity_score": 55,
    "logic_score": 90,
    "efficiency_score": 75,
    "model_family": "R1",
    "name_within_family": "0528"
  },
  {
    "id": 206,
    "vendor_id": 15,
    "api_id": "meta-llama/llama-3.1-405b-instruct",
    "slug": "llama-3.1-405b-instruct",
    "display_name": "Llama 3.1 405B Instruct",
    "display_order": 40,
    "description": "World's largest open-source LLM - rivals GPT-4 and Claude 3.5\n\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 10000,
    "price_prompt_micro": 3500000,
    "price_completion_micro": 3500000,
    "price_tier": 2,
    "fallback_model_id": 96,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:46:45.095485+00:00",
    "parameter_count_b": 405,
    "personality_traits": [
      "Frontier-Class"
    ],
    "professional_traits": [
      "LLM-as-judge",
      "knowledge distillation"
    ],
    "best_for": [
      "Synthetic data generation"
    ],
    "active_parameter_count_b": 405,
    "creativity_score": 85,
    "logic_score": 90,
    "efficiency_score": 50,
    "model_family": "Llama",
    "name_within_family": "3.1 405B Instruct"
  },
  {
    "id": 126,
    "vendor_id": 9,
    "api_id": "deepseek/deepseek-v3.1-terminus",
    "slug": "deepseek-v3.1-terminus",
    "display_name": "DeepSeek V3.1 Terminus",
    "display_order": 40,
    "description": "Stabilized V3.1 with improved agentic capabilities",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 163840,
    "price_prompt_micro": 210000,
    "price_completion_micro": 790000,
    "price_tier": 2,
    "fallback_model_id": 202,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:20:41.268583+00:00",
    "parameter_count_b": 686,
    "personality_traits": [
      "Stable"
    ],
    "professional_traits": [
      "thinking mode"
    ],
    "best_for": [
      "Production workflows",
      "multilingual applications"
    ],
    "active_parameter_count_b": 37,
    "creativity_score": 65,
    "logic_score": 85,
    "efficiency_score": 86,
    "model_family": "V3.1",
    "name_within_family": "V3.1 Terminus"
  },
  {
    "id": 91,
    "vendor_id": 18,
    "api_id": "mistralai/devstral-2512:free",
    "slug": "devstral-2512:free",
    "display_name": "Devstral 2 2512",
    "display_order": 0,
    "description": "Frontier agentic coding model for software engineering",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 262144,
    "price_prompt_micro": 0,
    "price_completion_micro": 0,
    "price_tier": 0,
    "fallback_model_id": 96,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:54:18.938799+00:00",
    "parameter_count_b": 123,
    "personality_traits": [
      "Precise",
      "Stepwise",
      "Self-Correcting",
      "Long-Horizon"
    ],
    "professional_traits": [
      "Code generation"
    ],
    "best_for": [
      "coding",
      "bug fixing",
      "legacy system modernization"
    ],
    "active_parameter_count_b": 123,
    "creativity_score": 45,
    "logic_score": 85,
    "efficiency_score": 70,
    "model_family": "Devstral",
    "name_within_family": "2 (2512)"
  },
  {
    "id": 1,
    "vendor_id": 6,
    "api_id": "bytedance-seed/seed-1.6-flash",
    "slug": "seed-1.6-flash",
    "display_name": "Seed 1.6 Flash",
    "display_order": 0,
    "description": "Ultra-fast multimodal deep thinking for real-time applications",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 75000,
    "price_completion_micro": 300000,
    "price_tier": 1,
    "fallback_model_id": 19,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 230,
    "personality_traits": [
      "Fast-Twitch",
      "Concise",
      "Intuitive",
      "Cost-Saver"
    ],
    "professional_traits": [],
    "best_for": [
      "low-latency applications"
    ],
    "active_parameter_count_b": 23,
    "creativity_score": 70,
    "logic_score": 75,
    "efficiency_score": 100,
    "model_family": "Seed",
    "name_within_family": "1.6 Flash"
  },
  {
    "id": 2,
    "vendor_id": 6,
    "api_id": "bytedance-seed/seed-1.6",
    "slug": "seed-1.6",
    "display_name": "Seed 1.6",
    "display_order": 10,
    "description": "Adaptive Chain-of-Thought reasoning with multimodal support",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 250000,
    "price_completion_micro": 2000000,
    "price_tier": 2,
    "fallback_model_id": 3,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 230,
    "personality_traits": [
      "Deep-Thinker",
      "Stepwise",
      "Analyst",
      "Self-Correcting",
      "Long-Horizon"
    ],
    "professional_traits": [
      "Adaptive thinking"
    ],
    "best_for": [
      "Complex reasoning",
      "academic tasks",
      "multimodal understanding",
      "GUI interaction"
    ],
    "active_parameter_count_b": 23,
    "creativity_score": 80,
    "logic_score": 90,
    "efficiency_score": 85,
    "model_family": "Seed",
    "name_within_family": "1.6"
  },
  {
    "id": 49,
    "vendor_id": 24,
    "api_id": "openai/o4-mini-deep-research",
    "slug": "o4-mini-deep-research",
    "display_name": "o4 Mini Deep Research",
    "display_order": 110,
    "description": "Faster, more affordable deep research",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 200000,
    "price_prompt_micro": 2000000,
    "price_completion_micro": 8000000,
    "price_tier": 3,
    "fallback_model_id": 188,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:35:14.47783+00:00",
    "parameter_count_b": 250,
    "personality_traits": [
      "Researcher",
      "Fast",
      "Cost-Efficient"
    ],
    "professional_traits": [
      "Web search",
      "synthesis"
    ],
    "best_for": [
      "High-volume research",
      "cost-sensitive research tasks"
    ],
    "active_parameter_count_b": 20,
    "creativity_score": 55,
    "logic_score": 80,
    "efficiency_score": 85,
    "model_family": "o",
    "name_within_family": "o4 Mini Deep Research"
  },
  {
    "id": 210,
    "vendor_id": 7,
    "api_id": "cohere/command-r-08-2024",
    "slug": "command-r-08-2024",
    "display_name": "Cohere: Command R (08-2024)",
    "display_order": 20,
    "description": "command-r-08-2024 is an update of the [Command R](/models/cohere/command-r) with improved performance for multilingual retrieval-augmented generation (RAG) and tool use.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 128000,
    "price_prompt_micro": 150000,
    "price_completion_micro": 600000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T16:53:58.535853+00:00",
    "parameter_count_b": 104,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Command R",
    "name_within_family": "+ 08-2024"
  },
  {
    "id": 138,
    "vendor_id": 35,
    "api_id": "x-ai/grok-4.1-fast",
    "slug": "grok-4.1-fast",
    "display_name": "Grok 4.1 Fast",
    "display_order": 0,
    "description": "Best-in-class agentic tool-calling model with 2M context and real-time search",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 2000000,
    "price_prompt_micro": 200000,
    "price_completion_micro": 500000,
    "price_tier": 1,
    "fallback_model_id": 139,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:10:41.633788+00:00",
    "parameter_count_b": 400,
    "personality_traits": [
      "Precise",
      "Tool-Seeker",
      "Fast-Twitch",
      "Analyst",
      "Long-Horizon",
      "Context-Heavy",
      "Assertive",
      "Extrovert"
    ],
    "professional_traits": [
      "web search",
      "X search",
      "code execution",
      "document retrieval",
      "MCP integration",
      "multimodal (images)",
      "real-time data access"
    ],
    "best_for": [
      "Enterprise agents",
      "customer support automation",
      "agentic search",
      "real-time information retrieval",
      "complex multi-step workflows",
      "finance applications"
    ],
    "active_parameter_count_b": 30,
    "creativity_score": 70,
    "logic_score": 85,
    "efficiency_score": 95,
    "model_family": "Grok",
    "name_within_family": "4.1 Fast"
  },
  {
    "id": 139,
    "vendor_id": 35,
    "api_id": "x-ai/grok-4-fast",
    "slug": "grok-4-fast",
    "display_name": "xAI: Grok 4 Fast",
    "display_order": 10,
    "description": "Grok 4 Fast is xAI's latest multimodal model with SOTA cost-efficiency and a 2M token context window.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 2000000,
    "price_prompt_micro": 200000,
    "price_completion_micro": 500000,
    "price_tier": 1,
    "fallback_model_id": 55,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Grok",
    "name_within_family": "4 Fast"
  },
  {
    "id": 21,
    "vendor_id": 11,
    "api_id": "google/gemini-2.5-pro",
    "slug": "gemini-2.5-pro",
    "display_name": "Gemini 2.5 Pro",
    "display_order": 90,
    "description": "Stable previous-gen flagship - strong for coding and agents",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 1048576,
    "price_prompt_micro": 1250000,
    "price_completion_micro": 10000000,
    "price_tier": 3,
    "fallback_model_id": 54,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:33:52.168231+00:00",
    "parameter_count_b": 1000,
    "personality_traits": [
      "Stable"
    ],
    "professional_traits": [
      "search grounding",
      "code execution"
    ],
    "best_for": [
      "Production workloads requiring stability",
      "coding"
    ],
    "active_parameter_count_b": 15,
    "creativity_score": 75,
    "logic_score": 85,
    "efficiency_score": 75,
    "model_family": "Gemini",
    "name_within_family": "2.5 Pro"
  },
  {
    "id": 130,
    "vendor_id": 9,
    "api_id": "deepseek/deepseek-r1-distill-qwen-32b",
    "slug": "deepseek-r1-distill-qwen-32b",
    "display_name": "DeepSeek: R1 Distill Qwen 32B",
    "display_order": 80,
    "description": "Distilled R1 reasoning into Qwen 2.5 32B - beats o1-mini",
    "capabilities": [
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 270000,
    "price_completion_micro": 270000,
    "price_tier": 1,
    "fallback_model_id": 181,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:25:28.144016+00:00",
    "parameter_count_b": 32,
    "personality_traits": [
      "Distilled-Reasoning",
      "Dense",
      "Local-Friendly"
    ],
    "professional_traits": [
      "Chain-of-thought reasoning"
    ],
    "best_for": [
      "cost-sensitive reasoning",
      "edge inference"
    ],
    "active_parameter_count_b": 32,
    "creativity_score": 50,
    "logic_score": 80,
    "efficiency_score": 90,
    "model_family": "R1 Distilled",
    "name_within_family": "Qwen 32B"
  },
  {
    "id": 14,
    "vendor_id": 11,
    "api_id": "google/gemini-3-pro-preview",
    "slug": "gemini-3-pro-preview",
    "display_name": "Gemini 3 Pro Preview",
    "display_order": 20,
    "description": "Gemini 3 Pro is Google’s flagship frontier model for high-precision multimodal reasoning, combining strong performance across text, image, video, audio, and code with a 1M-token context window.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 1048576,
    "price_prompt_micro": 2000000,
    "price_completion_micro": 12000000,
    "price_tier": 3,
    "fallback_model_id": 141,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:28:23.266424+00:00",
    "parameter_count_b": 1200,
    "personality_traits": [
      "Thorough",
      "Authoritative",
      "Scholarly",
      "Precise",
      "Measured",
      "Professional",
      "Comprehensive",
      "Cautious",
      "Formal",
      "Detailed"
    ],
    "professional_traits": [
      "Intelligent",
      "Deep-Thinker"
    ],
    "best_for": [
      "Research",
      "complex reasoning",
      "PhD-level problems",
      "multimodal analysis",
      "long documents"
    ],
    "active_parameter_count_b": 20,
    "creativity_score": 85,
    "logic_score": 100,
    "efficiency_score": 70,
    "model_family": "Gemini",
    "name_within_family": "3 Pro Preview"
  },
  {
    "id": 147,
    "vendor_id": 14,
    "api_id": "kwaipilot/kat-coder-pro:free",
    "slug": "kat-coder-pro:free",
    "display_name": "Kwaipilot: KAT-Coder-Pro V1",
    "display_order": 0,
    "description": "KAT-Coder-Pro V1 is KwaiKAT's most advanced agentic coding model in the KAT-Coder series.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 256000,
    "price_prompt_micro": 0,
    "price_completion_micro": 0,
    "price_tier": 0,
    "fallback_model_id": 170,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 40,
    "personality_traits": [
      "Precise",
      "Tool-Seeker",
      "Stepwise",
      "Deep-Thinker",
      "Analyst"
    ],
    "professional_traits": [],
    "best_for": [
      "software engineering"
    ],
    "active_parameter_count_b": 10,
    "creativity_score": 65,
    "logic_score": 95,
    "efficiency_score": 85,
    "model_family": "KAT-Coder",
    "name_within_family": "Pro V1"
  },
  {
    "id": 12,
    "vendor_id": 11,
    "api_id": "google/gemini-3-flash-preview",
    "slug": "gemini-3-flash-preview",
    "display_name": "Gemini 3 Flash Preview",
    "display_order": 0,
    "description": "Frontier intelligence at Flash speed - beats 2.5 Pro on 18/20 benchmarks\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 1048576,
    "price_prompt_micro": 500000,
    "price_completion_micro": 3000000,
    "price_tier": 2,
    "fallback_model_id": 138,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:34:10.898989+00:00",
    "parameter_count_b": 300,
    "personality_traits": [
      "Speed-King",
      "Value-Leader",
      "Pro-Grade-Reasoning"
    ],
    "professional_traits": [
      "code execution",
      "thinking budget control",
      "search grounding"
    ],
    "best_for": [
      "Production workloads",
      "high-volume tasks",
      "real-time applications"
    ],
    "active_parameter_count_b": 10,
    "creativity_score": 75,
    "logic_score": 90,
    "efficiency_score": 100,
    "model_family": "Gemini",
    "name_within_family": "3 Flash Preview"
  },
  {
    "id": 26,
    "vendor_id": 11,
    "api_id": "google/gemma-3-27b-it:free",
    "slug": "gemma-3-27b-it:free",
    "display_name": "Gemma 3 27B",
    "display_order": 140,
    "description": "Best open-source multimodal model from Google",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 0,
    "price_completion_micro": 0,
    "price_tier": 0,
    "fallback_model_id": 35,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:40:14.181056+00:00",
    "parameter_count_b": 27,
    "personality_traits": [],
    "professional_traits": [
      "vision understanding"
    ],
    "best_for": [],
    "active_parameter_count_b": 27,
    "creativity_score": 65,
    "logic_score": 75,
    "efficiency_score": 90,
    "model_family": "Gemma",
    "name_within_family": "3 27B"
  },
  {
    "id": 188,
    "vendor_id": 1,
    "api_id": "alibaba/tongyi-deepresearch-30b-a3b",
    "slug": "tongyi-deepresearch-30b-a3b",
    "display_name": "Tongyi DeepResearch 30B A3B",
    "display_order": 0,
    "description": "Purpose-built agentic LLM for deep research and web browsing",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 90000,
    "price_completion_micro": 400000,
    "price_tier": 1,
    "fallback_model_id": 120,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 31,
    "personality_traits": [
      "ool-Seeker",
      "Stepwise",
      "Analyst",
      "Context-Heavy",
      "Explore-Focused"
    ],
    "professional_traits": [
      "web browsing",
      "multi-source synthesis"
    ],
    "best_for": [
      "Deep research",
      "web browsing",
      "multi-step information synthesis"
    ],
    "active_parameter_count_b": 3,
    "creativity_score": 65,
    "logic_score": 80,
    "efficiency_score": 95,
    "model_family": "Tongyi",
    "name_within_family": "DeepResearch 30B A3B"
  },
  {
    "id": 141,
    "vendor_id": 35,
    "api_id": "x-ai/grok-4",
    "slug": "grok-4",
    "display_name": "Grok 4",
    "display_order": 30,
    "description": "xAI's flagship \"smartest AI in the world\" reasoning model",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 256000,
    "price_prompt_micro": 3000000,
    "price_completion_micro": 15000000,
    "price_tier": 3,
    "fallback_model_id": 63,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:15:40.928233+00:00",
    "parameter_count_b": 2200,
    "personality_traits": [
      "Precise",
      "Deep-Thinker",
      "Analyst",
      "Visionary",
      "Assertive",
      "Tool-Seeker",
      "Long-Horizon"
    ],
    "professional_traits": [
      "Advanced reasoning",
      "real-time search"
    ],
    "best_for": [
      "Complex research",
      "heavy reasoning tasks",
      "scientific analysis",
      "PhD-level problem solving",
      "business simulation",
      "long-horizon planning"
    ],
    "active_parameter_count_b": 140,
    "creativity_score": 65,
    "logic_score": 95,
    "efficiency_score": 40,
    "model_family": "Grok",
    "name_within_family": "4"
  },
  {
    "id": 189,
    "vendor_id": 25,
    "api_id": "opengvlab/internvl3-78b",
    "slug": "internvl3-78b",
    "display_name": "InternVL3 78B",
    "display_order": 0,
    "description": "SOTA open-source multimodal model rivaling GPT-4o",
    "capabilities": [],
    "context_length": 32768,
    "price_prompt_micro": 100000,
    "price_completion_micro": 390000,
    "price_tier": 1,
    "fallback_model_id": 184,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 78,
    "personality_traits": [
      "Analyst",
      "Context-Heavy",
      "Precise",
      "Deep-Thinker",
      "Premium-Tier"
    ],
    "professional_traits": [
      "Image understanding",
      "video processing",
      "OCR",
      "document analysis",
      "chart interpretation",
      "3D vision"
    ],
    "best_for": [
      "Multimodal reasoning",
      "document analysis",
      "video understanding"
    ],
    "active_parameter_count_b": 78,
    "creativity_score": 80,
    "logic_score": 85,
    "efficiency_score": 70,
    "model_family": "InternVL",
    "name_within_family": "3 78B"
  },
  {
    "id": 162,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-next-80b-a3b-thinking",
    "slug": "qwen3-next-80b-a3b-thinking",
    "display_name": "Qwen3 Next 80B A3B Thinking",
    "display_order": 80,
    "description": "Next-gen architecture with 10x throughput at 10% training cost",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 150000,
    "price_completion_micro": 1200000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:23:06.731048+00:00",
    "parameter_count_b": 80,
    "personality_traits": [
      "Precise",
      "Deep-Thinker",
      "Stepwise",
      "Analyst",
      "Innovative",
      "Self-Correcting"
    ],
    "professional_traits": [
      "Extended reasoning traces",
      "ultra-long context"
    ],
    "best_for": [
      "Complex reasoning requiring efficiency",
      "math proofs",
      "code synthesis",
      "agentic planning",
      "ultra-long-context tasks"
    ],
    "active_parameter_count_b": 3,
    "creativity_score": 50,
    "logic_score": 85,
    "efficiency_score": 95,
    "model_family": "Qwen3 Next",
    "name_within_family": "80B A3B Thinking"
  },
  {
    "id": 193,
    "vendor_id": 22,
    "api_id": "nousresearch/hermes-3-llama-3.1-70b",
    "slug": "hermes-3-llama-3.1-70b",
    "display_name": "Nous: Hermes 3 70B Instruct",
    "display_order": 20,
    "description": "Flagship generalist with advanced agentic capabilities",
    "capabilities": [],
    "context_length": 65536,
    "price_prompt_micro": 300000,
    "price_completion_micro": 300000,
    "price_tier": 1,
    "fallback_model_id": 204,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 70,
    "personality_traits": [
      "Steerable",
      "Agentic",
      "Creative",
      "Coherent",
      "User-Aligned",
      "Roleplayer",
      "Long-Context",
      "Multi-Turn",
      "Tool-User",
      "Persona-Maintainer"
    ],
    "professional_traits": [
      "Internal Monologue",
      "Long-Context Coherence"
    ],
    "best_for": [
      "Sophisticated AI assistants",
      "interactive storytelling and roleplay",
      "agentic workflows with tool use",
      "extended multi-turn conversations",
      "RAG applications",
      "character-based interactions requiring consistency"
    ],
    "active_parameter_count_b": 70,
    "creativity_score": 80,
    "logic_score": 70,
    "efficiency_score": 70,
    "model_family": "Hermes",
    "name_within_family": "3 70B Instruct"
  },
  {
    "id": 163,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-next-80b-a3b-instruct",
    "slug": "qwen3-next-80b-a3b-instruct",
    "display_name": "Qwen3 Next 80B A3B Instruct",
    "display_order": 90,
    "description": "Performance of 235B at fraction of cost with next-gen architecture",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 262144,
    "price_prompt_micro": 60000,
    "price_completion_micro": 600000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:24:32.176679+00:00",
    "parameter_count_b": 80,
    "personality_traits": [
      "Precise",
      "Fast-Twitch",
      "Tool-Seeker",
      "Analyst",
      "Cost-Saver"
    ],
    "professional_traits": [
      "Fast inference",
      "ultra-long context"
    ],
    "best_for": [
      "High-volume production",
      "cost-sensitive deployments",
      "long-document processing",
      "efficient instruction following"
    ],
    "active_parameter_count_b": 3,
    "creativity_score": 50,
    "logic_score": 75,
    "efficiency_score": 95,
    "model_family": "Qwen3 Next",
    "name_within_family": "80B A3B Instruct"
  },
  {
    "id": 220,
    "vendor_id": 24,
    "api_id": "openai/gpt-5.2-codex",
    "slug": "gpt-5.2-codex",
    "display_name": "GPT-5.2-Codex",
    "display_order": 0,
    "description": "OpenAI's most advanced agentic coding model for long-horizon software engineering",
    "capabilities": [],
    "context_length": 400384,
    "price_prompt_micro": 2000000,
    "price_completion_micro": 1400000,
    "price_tier": 1,
    "fallback_model_id": 41,
    "is_active": true,
    "last_synced_at": "2026-01-19T06:53:16.760306+00:00",
    "created_at": "2026-01-19T06:53:16.760306+00:00",
    "updated_at": "2026-01-19T08:11:25.288342+00:00",
    "parameter_count_b": 2200,
    "personality_traits": [
      "Persistent",
      "Methodical",
      "Thorough",
      "Patient",
      "Detail-Oriented",
      "Tireless",
      "Systematic",
      "Focused",
      "Instruction-Adherent",
      "Diligent"
    ],
    "professional_traits": [
      "Long-Horizon",
      "Context-Compaction",
      "Code-Review"
    ],
    "best_for": [
      "Large-scale code refactors and migrations",
      "security vulnerability research",
      "complex debugging across large repositories",
      "Windows development",
      "CI/CD automation",
      "enterprise software engineering"
    ],
    "active_parameter_count_b": 75,
    "creativity_score": 40,
    "logic_score": 95,
    "efficiency_score": 60,
    "model_family": "Codex",
    "name_within_family": "5.2-Codex"
  },
  {
    "id": 42,
    "vendor_id": 24,
    "api_id": "openai/gpt-5.1",
    "slug": "gpt-5.1",
    "display_name": "GPT-5.1",
    "display_order": 40,
    "description": "Warmer, more conversational GPT-5 with adaptive reasoning",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 400000,
    "price_prompt_micro": 1250000,
    "price_completion_micro": 10000000,
    "price_tier": 3,
    "fallback_model_id": 136,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:18:07.027001+00:00",
    "parameter_count_b": 2000,
    "personality_traits": [
      "Warm",
      "Conversational",
      "Adaptive",
      "Precise",
      "Instruction-Following"
    ],
    "professional_traits": [
      "Vision",
      "structured outputs",
      "style customization",
      "adaptive reasoning"
    ],
    "best_for": [
      "Conversational AI",
      "customer-facing applications",
      "personalized assistants"
    ],
    "active_parameter_count_b": 110,
    "creativity_score": 75,
    "logic_score": 85,
    "efficiency_score": 80,
    "model_family": "GPT-5",
    "name_within_family": "5.1"
  },
  {
    "id": 48,
    "vendor_id": 24,
    "api_id": "openai/o3-deep-research",
    "slug": "o3-deep-research",
    "display_name": "o3 Deep Research",
    "display_order": 100,
    "description": "Most powerful deep research model - multi-step web research agent",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 200000,
    "price_prompt_micro": 10000000,
    "price_completion_micro": 40000000,
    "price_tier": 3,
    "fallback_model_id": 49,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:33:49.047159+00:00",
    "parameter_count_b": 3000,
    "personality_traits": [
      "Researcher",
      "Synthesizer",
      "Multi-Step",
      "Web-Native"
    ],
    "professional_traits": [
      "Web search",
      "synthesis",
      "report generation"
    ],
    "best_for": [
      "Complex research tasks",
      "market analysis",
      "literature reviews",
      "competitive intelligence"
    ],
    "active_parameter_count_b": 200,
    "creativity_score": 60,
    "logic_score": 90,
    "efficiency_score": 50,
    "model_family": "o",
    "name_within_family": "o3 Deep Research"
  },
  {
    "id": 39,
    "vendor_id": 24,
    "api_id": "openai/gpt-5.2-pro",
    "slug": "gpt-5.2-pro",
    "display_name": "GPT-5.2 Pro",
    "display_order": 10,
    "description": "GPT-5.2 Pro is OpenAI’s most advanced model, offering major improvements in agentic coding and long context performance over GPT-5 Pro.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 400000,
    "price_prompt_micro": 21000000,
    "price_completion_micro": 168000000,
    "price_tier": 3,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "GPT-5",
    "name_within_family": "5.2 Pro"
  },
  {
    "id": 33,
    "vendor_id": 2,
    "api_id": "allenai/olmo-3-7b-instruct",
    "slug": "olmo-3-7b-instruct",
    "display_name": "Olmo 3 7B Instruct",
    "display_order": 20,
    "description": "Olmo 3 7B Instruct is a supervised instruction-fine-tuned variant of the Olmo 3 7B base model, optimized for instruction-following, question-answering, and natural conversational dialogue.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 65536,
    "price_prompt_micro": 100000,
    "price_completion_micro": 200000,
    "price_tier": 1,
    "fallback_model_id": 205,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 7,
    "personality_traits": [
      "Analyst",
      "Self-Correcting",
      "Cautious",
      "Didactic",
      "Tool-Seeker"
    ],
    "professional_traits": [],
    "best_for": [],
    "active_parameter_count_b": 7,
    "creativity_score": 70,
    "logic_score": 85,
    "efficiency_score": 85,
    "model_family": "OLMo",
    "name_within_family": "OLMo 3 7B"
  },
  {
    "id": 41,
    "vendor_id": 24,
    "api_id": "openai/gpt-5.1-codex-max",
    "slug": "gpt-5.1-codex-max",
    "display_name": "GPT-5.1-Codex-Max",
    "display_order": 30,
    "description": "Previous frontier agentic coding - first with native compaction",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 400000,
    "price_prompt_micro": 1250000,
    "price_completion_micro": 10000000,
    "price_tier": 3,
    "fallback_model_id": 91,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-19T08:10:39.375624+00:00",
    "parameter_count_b": 2000,
    "personality_traits": [
      "Precise",
      "Tool-Seeker",
      "Agentic",
      "Long-Horizon",
      "Compaction-Native"
    ],
    "professional_traits": [
      "Code generation",
      "compaction"
    ],
    "best_for": [
      "Long-running coding tasks",
      "project-scale refactors",
      "deep debugging"
    ],
    "active_parameter_count_b": 120,
    "creativity_score": 45,
    "logic_score": 90,
    "efficiency_score": 80,
    "model_family": "Codex",
    "name_within_family": "5.1-Codex-Max"
  },
  {
    "id": 36,
    "vendor_id": 23,
    "api_id": "nvidia/nemotron-nano-9b-v2:free",
    "slug": "nemotron-nano-9b-v2:free",
    "display_name": "Nemotron Nano 9B V2",
    "display_order": 10,
    "description": "3-6x faster than Qwen3-8B with comparable accuracy",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 128000,
    "price_prompt_micro": 0,
    "price_completion_micro": 0,
    "price_tier": 0,
    "fallback_model_id": 33,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 9,
    "personality_traits": [
      "Concise",
      "Fast-Twitch",
      "Cost-Saver",
      "Intuitive",
      "Tool-Seeker"
    ],
    "professional_traits": [
      "reasoning budget control"
    ],
    "best_for": [
      "budget inference"
    ],
    "active_parameter_count_b": 9,
    "creativity_score": 70,
    "logic_score": 80,
    "efficiency_score": 100,
    "model_family": "Nemotron",
    "name_within_family": "Nano 9B V2"
  },
  {
    "id": 65,
    "vendor_id": 24,
    "api_id": "openai/gpt-4.1",
    "slug": "gpt-4.1",
    "display_name": "GPT-4.1",
    "display_order": 270,
    "description": "1M context, instruction-following champion",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 1047576,
    "price_prompt_micro": 2000000,
    "price_completion_micro": 8000000,
    "price_tier": 3,
    "fallback_model_id": 42,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:38:04.881493+00:00",
    "parameter_count_b": 1800,
    "personality_traits": [
      "Precise",
      "Tool-Master",
      "Long-Context",
      "Instruction-Follower"
    ],
    "professional_traits": [
      "Vision"
    ],
    "best_for": [
      "Long document processing",
      "instruction-heavy tasks"
    ],
    "active_parameter_count_b": 100,
    "creativity_score": 65,
    "logic_score": 80,
    "efficiency_score": 85,
    "model_family": "GPT-4.1",
    "name_within_family": "4.1"
  },
  {
    "id": 66,
    "vendor_id": 24,
    "api_id": "openai/gpt-4.1-mini",
    "slug": "gpt-4.1-mini",
    "display_name": "GPT-4.1 Mini",
    "display_order": 280,
    "description": "Beats GPT-4o at 83% lower cost",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 1047576,
    "price_prompt_micro": 400000,
    "price_completion_micro": 1600000,
    "price_tier": 2,
    "fallback_model_id": 20,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:39:07.47638+00:00",
    "parameter_count_b": 50,
    "personality_traits": [
      "Fast-Twitch",
      "Precise",
      "Cost-Saver",
      "Long-Context"
    ],
    "professional_traits": [
      "Vision"
    ],
    "best_for": [],
    "active_parameter_count_b": 10,
    "creativity_score": 55,
    "logic_score": 75,
    "efficiency_score": 95,
    "model_family": "GPT-4.1",
    "name_within_family": "4.1 Mini"
  },
  {
    "id": 55,
    "vendor_id": 24,
    "api_id": "openai/gpt-5-mini",
    "slug": "gpt-5-mini",
    "display_name": "GPT-5 Mini",
    "display_order": 170,
    "description": "Cost-efficient GPT-5 for well-defined tasks",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 400000,
    "price_prompt_micro": 250000,
    "price_completion_micro": 2000000,
    "price_tier": 2,
    "fallback_model_id": 66,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:22:28.183819+00:00",
    "parameter_count_b": 300,
    "personality_traits": [
      "Ultra-Fast",
      "Cost-Saver",
      "Classification-Focused"
    ],
    "professional_traits": [
      "Vision"
    ],
    "best_for": [
      "Classification",
      "summarization",
      "routing",
      "high-volume simple tasks"
    ],
    "active_parameter_count_b": 20,
    "creativity_score": 60,
    "logic_score": 80,
    "efficiency_score": 90,
    "model_family": "GPT-5",
    "name_within_family": "5 Mini"
  },
  {
    "id": 54,
    "vendor_id": 24,
    "api_id": "openai/gpt-5",
    "slug": "gpt-5",
    "display_name": "GPT-5",
    "display_order": 160,
    "description": "Unified reasoning system - smart router decides when to think",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 400000,
    "price_prompt_micro": 1250000,
    "price_completion_micro": 10000000,
    "price_tier": 3,
    "fallback_model_id": 42,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:22:58.659047+00:00",
    "parameter_count_b": 2000,
    "personality_traits": [
      "General-purpose flagship",
      "coding",
      "health queries",
      "multimodal tasks"
    ],
    "professional_traits": [
      "Vision",
      "tool calling",
      "reasoning (auto-routed)",
      "health expertise"
    ],
    "best_for": [
      "Precise",
      "Analyst",
      "Tool-Seeker",
      "Health-Aware"
    ],
    "active_parameter_count_b": 120,
    "creativity_score": 70,
    "logic_score": 90,
    "efficiency_score": 75,
    "model_family": "GPT-5",
    "name_within_family": "5"
  },
  {
    "id": 56,
    "vendor_id": 24,
    "api_id": "openai/gpt-5-nano",
    "slug": "gpt-5-nano",
    "display_name": "GPT-5 Nano",
    "display_order": 180,
    "description": "Fastest, cheapest GPT-5 variant for simple tasks\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 400000,
    "price_prompt_micro": 50000,
    "price_completion_micro": 400000,
    "price_tier": 1,
    "fallback_model_id": 67,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:24:23.850782+00:00",
    "parameter_count_b": 4,
    "personality_traits": [
      "Ultra-Fast",
      "Cost-Saver",
      "Classification-Focused"
    ],
    "professional_traits": [],
    "best_for": [
      "Classification",
      "summarization",
      "routing",
      "high-volume simple tasks"
    ],
    "active_parameter_count_b": 4,
    "creativity_score": 50,
    "logic_score": 65,
    "efficiency_score": 100,
    "model_family": "GPT-5",
    "name_within_family": "5 Nano"
  },
  {
    "id": 60,
    "vendor_id": 24,
    "api_id": "openai/o3-pro",
    "slug": "o3-pro",
    "display_name": "o3 Pro",
    "display_order": 220,
    "description": "Maximum compute o3 for highest reliability",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 200000,
    "price_prompt_micro": 20000000,
    "price_completion_micro": 80000000,
    "price_tier": 3,
    "fallback_model_id": 63,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:29:23.233057+00:00",
    "parameter_count_b": 3000,
    "personality_traits": [
      "Deep-Thinker",
      "Ultra-Reliable",
      "Mission-Critical",
      "Slower"
    ],
    "professional_traits": [
      "Vision",
      "web search",
      "Python",
      "memory"
    ],
    "best_for": [
      "Mission-critical tasks",
      "high-stakes decisions",
      "scientific proofs",
      "maximum accuracy requirements"
    ],
    "active_parameter_count_b": 300,
    "creativity_score": 55,
    "logic_score": 98,
    "efficiency_score": 50,
    "model_family": "o",
    "name_within_family": "o3 Pro"
  },
  {
    "id": 64,
    "vendor_id": 24,
    "api_id": "openai/o4-mini",
    "slug": "o4-mini",
    "display_name": "o4 Mini",
    "display_order": 260,
    "description": "Fast, cost-efficient reasoning - SOTA on AIME",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 200000,
    "price_prompt_micro": 1100000,
    "price_completion_micro": 4400000,
    "price_tier": 2,
    "fallback_model_id": 142,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:30:49.745276+00:00",
    "parameter_count_b": 250,
    "personality_traits": [
      "Fast-Twitch",
      "Precise",
      "Cost-Saver",
      "Math-Strong",
      "Visual"
    ],
    "professional_traits": [
      "Vision",
      "Python",
      "browsing"
    ],
    "best_for": [
      "High-volume reasoning",
      "math tasks",
      "coding at scale",
      "cost-sensitive reasoning"
    ],
    "active_parameter_count_b": 15,
    "creativity_score": 50,
    "logic_score": 85,
    "efficiency_score": 95,
    "model_family": "o",
    "name_within_family": "o4 Mini"
  },
  {
    "id": 62,
    "vendor_id": 24,
    "api_id": "openai/o4-mini-high",
    "slug": "o4-mini-high",
    "display_name": "o4 Mini High",
    "display_order": 240,
    "description": "Higher reasoning effort o4-mini for complex tasks",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 200000,
    "price_prompt_micro": 1100000,
    "price_completion_micro": 4400000,
    "price_tier": 2,
    "fallback_model_id": 64,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:32:24.746437+00:00",
    "parameter_count_b": 250,
    "personality_traits": [
      "Fast-Twitch",
      "Precise",
      "Enhanced-Reasoning"
    ],
    "professional_traits": [
      "Vision"
    ],
    "best_for": [
      "Complex reasoning at scale",
      "when accuracy matters more than speed"
    ],
    "active_parameter_count_b": 30,
    "creativity_score": 50,
    "logic_score": 90,
    "efficiency_score": 85,
    "model_family": "o",
    "name_within_family": "o4 Mini High"
  },
  {
    "id": 57,
    "vendor_id": 24,
    "api_id": "openai/gpt-oss-120b",
    "slug": "gpt-oss-120b",
    "display_name": "gpt-oss-120b",
    "display_order": 190,
    "description": "penAI's flagship open-weight model - Apache 2.0",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 20000,
    "price_completion_micro": 100000,
    "price_tier": 1,
    "fallback_model_id": 7,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:41:58.140565+00:00",
    "parameter_count_b": 117,
    "personality_traits": [],
    "professional_traits": [
      "web browsing",
      "Python execution"
    ],
    "best_for": [],
    "active_parameter_count_b": 5,
    "creativity_score": 50,
    "logic_score": 85,
    "efficiency_score": 90,
    "model_family": "GPT-OSS",
    "name_within_family": "120b"
  },
  {
    "id": 59,
    "vendor_id": 24,
    "api_id": "openai/gpt-oss-20b",
    "slug": "gpt-oss-20b",
    "display_name": "gpt-oss-20b",
    "display_order": 210,
    "description": "Lightweight open-weight for edge and local",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 16000,
    "price_completion_micro": 60000,
    "price_tier": 1,
    "fallback_model_id": 11,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:42:48.02921+00:00",
    "parameter_count_b": 21,
    "personality_traits": [
      "Cost-Saver"
    ],
    "professional_traits": [],
    "best_for": [],
    "active_parameter_count_b": 4,
    "creativity_score": 45,
    "logic_score": 75,
    "efficiency_score": 95,
    "model_family": "GPT-OSS",
    "name_within_family": "20b"
  },
  {
    "id": 205,
    "vendor_id": 15,
    "api_id": "meta-llama/llama-3.1-8b-instruct",
    "slug": "llama-3.1-8b-instruct",
    "display_name": "Llama 3.1 8B Instruct",
    "display_order": 30,
    "description": "Most accessible Llama - runs on consumer hardware",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 20000,
    "price_completion_micro": 30000,
    "price_tier": 1,
    "fallback_model_id": 94,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:47:56.045177+00:00",
    "parameter_count_b": 8,
    "personality_traits": [
      "Lightweight",
      "Fast"
    ],
    "professional_traits": [
      "multilingual"
    ],
    "best_for": [
      "resource-constrained"
    ],
    "active_parameter_count_b": 8,
    "creativity_score": 60,
    "logic_score": 65,
    "efficiency_score": 100,
    "model_family": "Llama",
    "name_within_family": "3.1 8B Instruct"
  },
  {
    "id": 71,
    "vendor_id": 24,
    "api_id": "openai/o3-mini-high",
    "slug": "o3-mini-high",
    "display_name": "o3 Mini High",
    "display_order": 330,
    "description": "OpenAI o3-mini-high is the same model as [o3-mini](/openai/o3-mini) with reasoning_effort set to high.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 200000,
    "price_prompt_micro": 1100000,
    "price_completion_micro": 4400000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "o",
    "name_within_family": "3 Mini High"
  },
  {
    "id": 204,
    "vendor_id": 15,
    "api_id": "meta-llama/llama-3.3-70b-instruct",
    "slug": "llama-3.3-70b-instruct",
    "display_name": "Llama 3.3 70B Instruct",
    "display_order": 20,
    "description": "405B performance at 70B cost - last Llama 3 release",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 100000,
    "price_completion_micro": 320000,
    "price_tier": 1,
    "fallback_model_id": 98,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:44:28.071622+00:00",
    "parameter_count_b": 70,
    "personality_traits": [
      "Balanced",
      "Production-Ready",
      "Cost-Effective",
      "Text-Only"
    ],
    "professional_traits": [],
    "best_for": [],
    "active_parameter_count_b": 70,
    "creativity_score": 75,
    "logic_score": 80,
    "efficiency_score": 90,
    "model_family": "Llama",
    "name_within_family": "3.3 70B Instruct"
  },
  {
    "id": 194,
    "vendor_id": 22,
    "api_id": "nousresearch/hermes-2-pro-llama-3-8b",
    "slug": "hermes-2-pro-llama-3-8b",
    "display_name": "NousResearch: Hermes 2 Pro - Llama-3 8B",
    "display_order": 30,
    "description": "Efficient agentic model optimized for function calling",
    "capabilities": [],
    "context_length": 8192,
    "price_prompt_micro": 25000,
    "price_completion_micro": 80000,
    "price_tier": 1,
    "fallback_model_id": 205,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 8,
    "personality_traits": [
      "Structured",
      "Efficient",
      "Versatile",
      "Tool-Focused",
      "Lightweight",
      "Fast"
    ],
    "professional_traits": [
      "Accuracy"
    ],
    "best_for": [
      "structured data extraction",
      "rapid prototyping",
      "budget-conscious workflows"
    ],
    "active_parameter_count_b": 8,
    "creativity_score": 60,
    "logic_score": 70,
    "efficiency_score": 90,
    "model_family": "Hermes",
    "name_within_family": "2 Pro - Llama-3 8B"
  },
  {
    "id": 195,
    "vendor_id": 34,
    "api_id": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
    "slug": "dolphin-mistral-24b-venice-edition:free",
    "display_name": "Uncensored",
    "display_order": 0,
    "description": "Most uncensored AI model with 2.2% refusal rate",
    "capabilities": [],
    "context_length": 32768,
    "price_prompt_micro": 0,
    "price_completion_micro": 0,
    "price_tier": 0,
    "fallback_model_id": 191,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 24,
    "personality_traits": [
      "Permissive",
      "Creative",
      "Guardrail-Lite",
      "Colloquial",
      "Roleplayer"
    ],
    "professional_traits": [
      "Web search",
      "minimal content filtering",
      "character creation"
    ],
    "best_for": [
      "Creative writing",
      "roleplay",
      "philosophical discussions",
      "unrestricted brainstorming"
    ],
    "active_parameter_count_b": null,
    "creativity_score": 90,
    "logic_score": 70,
    "efficiency_score": 80,
    "model_family": "Venice",
    "name_within_family": "Uncensored"
  },
  {
    "id": 212,
    "vendor_id": 16,
    "api_id": "microsoft/phi-4",
    "slug": "phi-4",
    "display_name": "Phi 4",
    "display_order": 0,
    "description": "[Microsoft Research](/microsoft) Phi-4 is designed to perform well in complex reasoning tasks and can operate efficiently in situations with limited memory or where quick responses are needed - especially math.",
    "capabilities": [],
    "context_length": 16384,
    "price_prompt_micro": 60000,
    "price_completion_micro": 140000,
    "price_tier": 1,
    "fallback_model_id": 36,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 14,
    "personality_traits": [
      "Deep-Thinker",
      "Stepwise",
      "Precise",
      "Analyst",
      "Assertive"
    ],
    "professional_traits": [
      "Competition math",
      "code generation",
      "logical reasoning",
      "instruction following"
    ],
    "best_for": [],
    "active_parameter_count_b": 5,
    "creativity_score": 70,
    "logic_score": 95,
    "efficiency_score": 90,
    "model_family": "Phi",
    "name_within_family": "Phi 4"
  },
  {
    "id": 213,
    "vendor_id": 28,
    "api_id": "sao10k/l3.3-euryale-70b",
    "slug": "l3.3-euryale-70b",
    "display_name": " Llama 3.3 Euryale 70B",
    "display_order": 0,
    "description": "Premier creative roleplay model with exceptional spatial awareness",
    "capabilities": [],
    "context_length": 131072,
    "price_prompt_micro": 650000,
    "price_completion_micro": 750000,
    "price_tier": 2,
    "fallback_model_id": 214,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 70,
    "personality_traits": [
      "Creative",
      "Spatial-Aware",
      "Character-Consistent",
      "Non-Restrictive",
      "Immersive",
      "Narrative-Driven",
      "Prompt-Adherent",
      "Uncensored",
      "Storyteller",
      "World-Builder"
    ],
    "professional_traits": [
      "Spatial Awareness",
      "Character Consistency",
      "Non-Restrictive Content",
      "Extended Narrative Coherence",
      "Environment Tracking"
    ],
    "best_for": [
      "Immersive storytelling",
      "character-driven roleplay",
      "interactive fiction",
      "creative writing assistance",
      "text-based adventure games",
      "extended narrative sessions",
      "world-building",
      "character embodiment"
    ],
    "active_parameter_count_b": 70,
    "creativity_score": 90,
    "logic_score": 60,
    "efficiency_score": 70,
    "model_family": "Llama",
    "name_within_family": "3.3 Euryale 70B"
  },
  {
    "id": 214,
    "vendor_id": 28,
    "api_id": "sao10k/l3.1-euryale-70b",
    "slug": "l3.1-euryale-70b",
    "display_name": "Llama 3.1 Euryale 70B v2.2",
    "display_order": 10,
    "description": "Refined creative roleplay model with Claude-enhanced datasets",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 32768,
    "price_prompt_micro": 650000,
    "price_completion_micro": 750000,
    "price_tier": 2,
    "fallback_model_id": 191,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 70,
    "personality_traits": [
      "Spatial-Aware",
      "Multi-Turn",
      "Creative",
      "Balanced",
      "Adherent",
      "Narrative-Focused",
      "Character-Driven",
      "Refined",
      "Coherent"
    ],
    "professional_traits": [
      "Spatial Awareness",
      "Reasoning Datasets",
      "Coherency",
      "Creative Writing"
    ],
    "best_for": [
      "Extended roleplay scenarios",
      "creative storytelling",
      "character-based interactions",
      "narrative content generation",
      "multi-turn creative sessions"
    ],
    "active_parameter_count_b": 70,
    "creativity_score": 85,
    "logic_score": 55,
    "efficiency_score": 65,
    "model_family": "Llama",
    "name_within_family": "3.1 Euryale 70B v2.2"
  },
  {
    "id": 216,
    "vendor_id": 20,
    "api_id": "neversleep/llama-3.1-lumimaid-8b",
    "slug": "llama-3.1-lumimaid-8b",
    "display_name": "NeverSleep: Lumimaid v0.2 8B",
    "display_order": 0,
    "description": "Lumimaid v0.2 8B is a finetune of [Llama 3.1 8B](/models/meta-llama/llama-3.1-8b-instruct) with a \"HUGE step up dataset wise\" compared to Lumimaid v0.1.",
    "capabilities": [],
    "context_length": 32768,
    "price_prompt_micro": 90000,
    "price_completion_micro": 600000,
    "price_tier": 1,
    "fallback_model_id": 215,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 8,
    "personality_traits": [
      "Creative",
      "Roleplayer",
      "Permissive",
      "Colloquial",
      "Storyteller"
    ],
    "professional_traits": [
      "Character consistency",
      "narrative generation",
      "minimal refusals"
    ],
    "best_for": [
      "Roleplay",
      "creative writing",
      "character interactions",
      "interactive fiction"
    ],
    "active_parameter_count_b": 8,
    "creativity_score": 90,
    "logic_score": 55,
    "efficiency_score": 85,
    "model_family": "Lumimaid",
    "name_within_family": "v0.2 8B"
  },
  {
    "id": 67,
    "vendor_id": 24,
    "api_id": "openai/gpt-4.1-nano",
    "slug": "gpt-4.1-nano",
    "display_name": "GPT-4.1 Nano",
    "display_order": 290,
    "description": "Fastest, cheapest model - sub-second responses",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 1047576,
    "price_prompt_micro": 100000,
    "price_completion_micro": 400000,
    "price_tier": 1,
    "fallback_model_id": 95,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:40:26.067536+00:00",
    "parameter_count_b": 4,
    "personality_traits": [
      "Ultra-Fast",
      "Classification-Focused",
      "Cost-Saver"
    ],
    "professional_traits": [],
    "best_for": [
      "Classification",
      "autocompletion",
      "routing",
      "real-time applications"
    ],
    "active_parameter_count_b": 4,
    "creativity_score": 45,
    "logic_score": 65,
    "efficiency_score": 100,
    "model_family": "GPT-4.1",
    "name_within_family": "4.1 Nano"
  },
  {
    "id": 199,
    "vendor_id": 5,
    "api_id": "baidu/ernie-4.5-300b-a47b",
    "slug": "ernie-4.5-300b-a47b",
    "display_name": "ERNIE 4.5 300B A47B ",
    "display_order": 0,
    "description": "Baidu's flagship that beats DeepSeek-V3 on 22/28 benchmarks",
    "capabilities": [],
    "context_length": 122880,
    "price_prompt_micro": null,
    "price_completion_micro": 1100000,
    "price_tier": 2,
    "fallback_model_id": 2,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T11:54:34.238818+00:00",
    "parameter_count_b": 300,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Context-Heavy",
      "Assertive",
      "Exploit-Focused"
    ],
    "professional_traits": [],
    "best_for": [
      "instruction following",
      "knowledge tasks",
      "bilingual applications"
    ],
    "active_parameter_count_b": 47,
    "creativity_score": 75,
    "logic_score": 85,
    "efficiency_score": 80,
    "model_family": "ERNIE",
    "name_within_family": "4.5 300B A47B "
  },
  {
    "id": 196,
    "vendor_id": 30,
    "api_id": "tencent/hunyuan-a13b-instruct",
    "slug": "hunyuan-a13b-instruct",
    "display_name": "Hunyuan A13B Instruct",
    "display_order": 0,
    "description": "Dual-mode reasoning (fast/slow) with leading agent capabilities",
    "capabilities": [
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 140000,
    "price_completion_micro": 570000,
    "price_tier": 1,
    "fallback_model_id": 199,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-19T08:07:28.943256+00:00",
    "parameter_count_b": 80,
    "personality_traits": [
      "Tool-Seeker",
      "Stepwise",
      "Analyst",
      "Assertive",
      "Exploit-Focused"
    ],
    "professional_traits": [],
    "best_for": [
      "math",
      "science",
      "reasoning"
    ],
    "active_parameter_count_b": 13,
    "creativity_score": 75,
    "logic_score": 85,
    "efficiency_score": 90,
    "model_family": "Hunyuan",
    "name_within_family": "A13B"
  },
  {
    "id": 73,
    "vendor_id": 24,
    "api_id": "openai/o1",
    "slug": "o1",
    "display_name": "o1",
    "display_order": 350,
    "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 200000,
    "price_prompt_micro": 15000000,
    "price_completion_micro": 60000000,
    "price_tier": 3,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T16:53:58.535853+00:00",
    "parameter_count_b": 1.3,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "o",
    "name_within_family": "1 Mini"
  },
  {
    "id": 217,
    "vendor_id": 20,
    "api_id": "neversleep/noromaid-20b",
    "slug": "noromaid-20b",
    "display_name": "Noromaid 20B",
    "display_order": 10,
    "description": "Larger roleplay model for enhanced character coherence and narrative depth",
    "capabilities": [],
    "context_length": 4096,
    "price_prompt_micro": 1000000,
    "price_completion_micro": 1750000,
    "price_tier": 2,
    "fallback_model_id": 216,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 20,
    "personality_traits": [
      "Creative",
      "Storyteller",
      "Roleplayer",
      "Permissive",
      "Verbose"
    ],
    "professional_traits": [
      "Long-form narratives",
      "character voice maintenance",
      "creative scenarios"
    ],
    "best_for": [
      "Roleplay",
      "ERP",
      "interactive fiction",
      "creative scenarios"
    ],
    "active_parameter_count_b": 20,
    "creativity_score": 90,
    "logic_score": 45,
    "efficiency_score": 70,
    "model_family": "Noromaid",
    "name_within_family": "20B"
  },
  {
    "id": 218,
    "vendor_id": 33,
    "api_id": "undi95/remm-slerp-l2-13b",
    "slug": "remm-slerp-l2-13b",
    "display_name": "SLERP 13B",
    "display_order": 0,
    "description": "A recreation trial of the original MythoMax-L2-B13 but with updated models.",
    "capabilities": [],
    "context_length": 6144,
    "price_prompt_micro": 450000,
    "price_completion_micro": 650000,
    "price_tier": 2,
    "fallback_model_id": 219,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 13,
    "personality_traits": [
      "Creative",
      "Storyteller",
      "Roleplayer",
      "Permissive",
      "Colloquial"
    ],
    "professional_traits": [
      "Character consistency",
      "narrative generation",
      "creative scenarios"
    ],
    "best_for": [
      "ERP",
      "interactive fiction",
      "creative writing"
    ],
    "active_parameter_count_b": 13,
    "creativity_score": 90,
    "logic_score": 50,
    "efficiency_score": 75,
    "model_family": "ReMM",
    "name_within_family": "SLERP 13B"
  },
  {
    "id": 96,
    "vendor_id": 18,
    "api_id": "mistralai/mistral-large-2512",
    "slug": "mistral-large-2512",
    "display_name": "Mistral Large 3 2512",
    "display_order": 50,
    "description": "Mistral's flagship multimodal MoE - enterprise-ready generalist",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 262144,
    "price_prompt_micro": 500000,
    "price_completion_micro": 1500000,
    "price_tier": 2,
    "fallback_model_id": 123,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:50:47.516556+00:00",
    "parameter_count_b": 675,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Formal",
      "Enterprise-Grade",
      "Context-Heavy"
    ],
    "professional_traits": [
      "Vision",
      "predicted outputs",
      "OCR",
      "prefix completion"
    ],
    "best_for": [
      "Enterprise assistants",
      "scientific workloads",
      "long document understanding"
    ],
    "active_parameter_count_b": 41,
    "creativity_score": 65,
    "logic_score": 85,
    "efficiency_score": 75,
    "model_family": "Large",
    "name_within_family": "3 2512"
  },
  {
    "id": 98,
    "vendor_id": 18,
    "api_id": "mistralai/mistral-medium-3.1",
    "slug": "mistral-medium-3.1",
    "display_name": "Mistral Medium 3.1",
    "display_order": 70,
    "description": "Enterprise workhorse - 90% of Sonnet 3.7 at fraction of cost",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 400000,
    "price_completion_micro": 2000000,
    "price_tier": 2,
    "fallback_model_id": 132,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:57:30.053806+00:00",
    "parameter_count_b": 200,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Formal",
      "Enterprise-Grade",
      "Cost-Saver"
    ],
    "professional_traits": [
      "Vision"
    ],
    "best_for": [
      "cost-conscious production"
    ],
    "active_parameter_count_b": 45,
    "creativity_score": 60,
    "logic_score": 80,
    "efficiency_score": 85,
    "model_family": "Mistral Medium",
    "name_within_family": "Medium 3.1"
  },
  {
    "id": 99,
    "vendor_id": 18,
    "api_id": "mistralai/codestral-2508",
    "slug": "codestral-2508",
    "display_name": "Codestral 2508",
    "display_order": 80,
    "description": "Mistral's cutting-edge language model for coding released end of July 2025.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 256000,
    "price_prompt_micro": 300000,
    "price_completion_micro": 900000,
    "price_tier": 2,
    "fallback_model_id": 183,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:00:13.225036+00:00",
    "parameter_count_b": 22,
    "personality_traits": [
      "Precise",
      "Stepwise",
      "Fast-Twitch",
      "Code-First"
    ],
    "professional_traits": [
      "code generation"
    ],
    "best_for": [
      "fill-in-the-middle",
      "code correction",
      "test generation"
    ],
    "active_parameter_count_b": 22,
    "creativity_score": 35,
    "logic_score": 75,
    "efficiency_score": 90,
    "model_family": "Codestral",
    "name_within_family": "2508"
  },
  {
    "id": 97,
    "vendor_id": 18,
    "api_id": "mistralai/voxtral-small-24b-2507",
    "slug": "voxtral-small-24b-2507",
    "display_name": "Voxtral Small 24B 2507",
    "display_order": 60,
    "description": "Voxtral Small is an enhancement of Mistral Small 3, incorporating state-of-the-art audio input capabilities while retaining best-in-class text performance.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 32000,
    "price_prompt_micro": 100000,
    "price_completion_micro": 300000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Voxtral",
    "name_within_family": "Small 24B 2507"
  },
  {
    "id": 94,
    "vendor_id": 18,
    "api_id": "mistralai/ministral-8b-2512",
    "slug": "ministral-8b-2512",
    "display_name": "Ministral 3 8B 2512",
    "display_order": 30,
    "description": "Balanced edge model with vision and reasoning",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 262144,
    "price_prompt_micro": 150000,
    "price_completion_micro": 150000,
    "price_tier": 1,
    "fallback_model_id": 36,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:03:05.190378+00:00",
    "parameter_count_b": 9,
    "personality_traits": [
      "Precise",
      "Fast-Twitch",
      "Cost-Saver"
    ],
    "professional_traits": [
      "Vision"
    ],
    "best_for": [
      "resource-constrained",
      "lightweight reasoning"
    ],
    "active_parameter_count_b": 8,
    "creativity_score": 45,
    "logic_score": 70,
    "efficiency_score": 95,
    "model_family": "Ministral",
    "name_within_family": "3 8B (2512)"
  },
  {
    "id": 219,
    "vendor_id": 12,
    "api_id": "gryphe/mythomax-l2-13b",
    "slug": "mythomax-l2-13b",
    "display_name": "MythoMax 13B",
    "display_order": 0,
    "description": "One of the highest performing and most popular fine-tunes of Llama 2 13B, with rich descriptions and roleplay.",
    "capabilities": [],
    "context_length": 4096,
    "price_prompt_micro": 60000,
    "price_completion_micro": 60000,
    "price_tier": 1,
    "fallback_model_id": 213,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 13,
    "personality_traits": [
      "Creative",
      "Storyteller",
      "Roleplayer",
      "Permissive",
      "Verbose"
    ],
    "professional_traits": [
      "Long-form storytelling",
      "character consistency",
      "narrative coherence"
    ],
    "best_for": [
      "Roleplay",
      "interactive fiction",
      "creative writing",
      "character-driven narratives"
    ],
    "active_parameter_count_b": 13,
    "creativity_score": 95,
    "logic_score": 55,
    "efficiency_score": 85,
    "model_family": "MythoMax",
    "name_within_family": "13B"
  },
  {
    "id": 95,
    "vendor_id": 18,
    "api_id": "mistralai/ministral-3b-2512",
    "slug": "ministral-3b-2512",
    "display_name": "Ministral 3 3B 2512",
    "display_order": 40,
    "description": "Tiny reasoning model - fits in 8GB RAM",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 100000,
    "price_completion_micro": 100000,
    "price_tier": 1,
    "fallback_model_id": 205,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:05:13.062083+00:00",
    "parameter_count_b": 4,
    "personality_traits": [
      "Fast-Twitch",
      "Ultra-Efficient"
    ],
    "professional_traits": [
      "Vision",
      "reasoning"
    ],
    "best_for": [
      "Efficient workflows"
    ],
    "active_parameter_count_b": 4,
    "creativity_score": 40,
    "logic_score": 60,
    "efficiency_score": 100,
    "model_family": "Ministral",
    "name_within_family": "3 3B (2512)"
  },
  {
    "id": 102,
    "vendor_id": 18,
    "api_id": "mistralai/mistral-small-3.2-24b-instruct",
    "slug": "mistral-small-3.2-24b-instruct",
    "display_name": "Mistral Small 3.2 24B",
    "display_order": 110,
    "description": "Latency-optimized multimodal - rivals 70B models at 3x speed",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 60000,
    "price_completion_micro": 180000,
    "price_tier": 1,
    "fallback_model_id": 120,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:59:06.575226+00:00",
    "parameter_count_b": 24,
    "personality_traits": [
      "Precise",
      "Fast-Twitch",
      "Cost-Saver"
    ],
    "professional_traits": [
      "Vision"
    ],
    "best_for": [
      "Fast-response assistants"
    ],
    "active_parameter_count_b": 24,
    "creativity_score": 55,
    "logic_score": 75,
    "efficiency_score": 95,
    "model_family": "Mistral Small",
    "name_within_family": "Small 3.2 24B"
  },
  {
    "id": 134,
    "vendor_id": 26,
    "api_id": "prime-intellect/intellect-3",
    "slug": "intellect-3",
    "display_name": "Prime Intellect: INTELLECT-3",
    "display_order": 0,
    "description": "SOTA reasoning model trained with large-scale RL on open infrastructure",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 200000,
    "price_completion_micro": 1100000,
    "price_tier": 2,
    "fallback_model_id": 191,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 106,
    "personality_traits": [
      "Deep-Thinker",
      "Stepwise",
      "Self-Correcting",
      "Assertive",
      "Tool-Seeker"
    ],
    "professional_traits": [
      "Math",
      "Reasoning"
    ],
    "best_for": [],
    "active_parameter_count_b": 12,
    "creativity_score": 75,
    "logic_score": 95,
    "efficiency_score": 85,
    "model_family": "INTELLECT",
    "name_within_family": "3"
  },
  {
    "id": 107,
    "vendor_id": 18,
    "api_id": "mistralai/mistral-small-24b-instruct-2501",
    "slug": "mistral-small-24b-instruct-2501",
    "display_name": "Mistral: Mistral Small 3",
    "display_order": 160,
    "description": "Mistral Small 3 is a 24B-parameter language model optimized for low-latency performance across common AI tasks.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 32768,
    "price_prompt_micro": 30000,
    "price_completion_micro": 110000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Mistral Small",
    "name_within_family": "Small 3"
  },
  {
    "id": 110,
    "vendor_id": 18,
    "api_id": "mistralai/pixtral-large-2411",
    "slug": "pixtral-large-2411",
    "display_name": "Mistral: Pixtral Large 2411",
    "display_order": 190,
    "description": "Frontier multimodal for documents and charts",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 2000000,
    "price_completion_micro": 6000000,
    "price_tier": 2,
    "fallback_model_id": 189,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:06:32.364896+00:00",
    "parameter_count_b": 124,
    "personality_traits": [
      "Precise",
      "Context-Heavy",
      "Analyst",
      "Vision-First"
    ],
    "professional_traits": [
      "Vision",
      "document parsing",
      "chart analysis"
    ],
    "best_for": [
      "Document analysis",
      "chart interpretation",
      "visual QA"
    ],
    "active_parameter_count_b": 124,
    "creativity_score": 55,
    "logic_score": 80,
    "efficiency_score": 65,
    "model_family": "Mistral Large",
    "name_within_family": "Pixtral Large 2411"
  },
  {
    "id": 119,
    "vendor_id": 10,
    "api_id": "essentialai/rnj-1-instruct",
    "slug": "rnj-1-instruct",
    "display_name": "EssentialAI: Rnj 1 Instruct",
    "display_order": 0,
    "description": " 8B model that beats 32B competitors on SWE-bench",
    "capabilities": [],
    "context_length": 32768,
    "price_prompt_micro": 150000,
    "price_completion_micro": 150000,
    "price_tier": 1,
    "fallback_model_id": 194,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:51:49.11627+00:00",
    "parameter_count_b": 8,
    "personality_traits": [],
    "professional_traits": [],
    "best_for": [],
    "active_parameter_count_b": 8,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Rnj",
    "name_within_family": "1 Instruct"
  },
  {
    "id": 122,
    "vendor_id": 9,
    "api_id": "deepseek/deepseek-v3.2-speciale",
    "slug": "deepseek-v3.2-speciale",
    "display_name": "DeepSeek V3.2 Speciale",
    "display_order": 0,
    "description": "Maximum reasoning - Gold medals in IMO, IOI, ICPC 2025",
    "capabilities": [
      "reasoning"
    ],
    "context_length": 163840,
    "price_prompt_micro": 270000,
    "price_completion_micro": 410000,
    "price_tier": 1,
    "fallback_model_id": 169,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-19T10:56:43.438892+00:00",
    "parameter_count_b": 685,
    "personality_traits": [
      "Ultra-Deep-Thinker",
      "Competition-Grade",
      "Math-Olympiad"
    ],
    "professional_traits": [],
    "best_for": [
      "Competition math",
      "olympiad problems",
      "complex proofs",
      "research-grade reasoning"
    ],
    "active_parameter_count_b": 36,
    "creativity_score": 50,
    "logic_score": 100,
    "efficiency_score": 50,
    "model_family": "V3.2",
    "name_within_family": "V3.2 Speciale"
  },
  {
    "id": 118,
    "vendor_id": 21,
    "api_id": "nex-agi/deepseek-v3.1-nex-n1:free",
    "slug": "deepseek-v3.1-nex-n1:free",
    "display_name": "DeepSeek V3.1 Nex N1",
    "display_order": 0,
    "description": "DeepSeek V3.1 Nex-N1 is the flagship release of the Nex-N1 series — a post-trained model designed to highlight agent autonomy, tool use, and real-world productivity.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 0,
    "price_completion_micro": 0,
    "price_tier": 0,
    "fallback_model_id": 5,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 670,
    "personality_traits": [
      "Tool-Seeker",
      "Stepwise",
      "Analyst",
      "Long-Horizon",
      "Assertive"
    ],
    "professional_traits": [
      "web search",
      "code generation",
      "autonomous research"
    ],
    "best_for": [
      "Agentic workflows",
      "deep research",
      "multi-step planning",
      "tool orchestration"
    ],
    "active_parameter_count_b": 31,
    "creativity_score": 70,
    "logic_score": 95,
    "efficiency_score": 80,
    "model_family": "Nex N1",
    "name_within_family": "Nex N1 "
  },
  {
    "id": 136,
    "vendor_id": 3,
    "api_id": "anthropic/claude-sonnet-4.5",
    "slug": "claude-sonnet-4.5",
    "display_name": "Anthropic: Claude Sonnet 4.5",
    "display_order": 10,
    "description": "Best coding model at mainstream pricing - 30+ hour task endurance",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 1000000,
    "price_prompt_micro": 3000000,
    "price_completion_micro": 15000000,
    "price_tier": 3,
    "fallback_model_id": 12,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:10:25.207307+00:00",
    "parameter_count_b": 200,
    "personality_traits": [
      "-Master",
      "Workhorse",
      "Value-Leader",
      "Long-Running",
      "Computer-User"
    ],
    "professional_traits": [],
    "best_for": [
      "Production coding",
      "daily AI tasks",
      "cost-conscious enterprise",
      "long-running agents"
    ],
    "active_parameter_count_b": 30,
    "creativity_score": 75,
    "logic_score": 85,
    "efficiency_score": 90,
    "model_family": "Claude",
    "name_within_family": "Sonnet 4.5"
  },
  {
    "id": 137,
    "vendor_id": 3,
    "api_id": "anthropic/claude-opus-4.1",
    "slug": "claude-opus-4.1",
    "display_name": "Anthropic: Claude Opus 4.1",
    "display_order": 20,
    "description": "Previous flagship - superseded by Opus 4.5 but still capable",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 200000,
    "price_prompt_micro": 15000000,
    "price_completion_micro": 75000000,
    "price_tier": 3,
    "fallback_model_id": 136,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:12:45.570366+00:00",
    "parameter_count_b": 1500,
    "personality_traits": [
      "Premium-Legacy",
      "Precision-Coder",
      "Detail-Oriented",
      "Research-Strong"
    ],
    "professional_traits": [
      "extended thinking",
      "precision debugging",
      "agentic search"
    ],
    "best_for": [
      "Legacy integrations",
      "users with existing contracts"
    ],
    "active_parameter_count_b": 60,
    "creativity_score": 80,
    "logic_score": 85,
    "efficiency_score": 65,
    "model_family": "Claude",
    "name_within_family": "Opus 4.1"
  },
  {
    "id": 132,
    "vendor_id": 9,
    "api_id": "deepseek/deepseek-r1-distill-llama-70b",
    "slug": "deepseek-r1-distill-llama-70b",
    "display_name": "R1 Distill Llama 70B",
    "display_order": 100,
    "description": "Distilled R1 reasoning into Llama 3.3 70B",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 30000,
    "price_completion_micro": 110000,
    "price_tier": 1,
    "fallback_model_id": 134,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:26:39.354076+00:00",
    "parameter_count_b": 70,
    "personality_traits": [],
    "professional_traits": [
      "Chain-of-thought reasoning"
    ],
    "best_for": [
      "enterprise deployment",
      "reasoning tasks"
    ],
    "active_parameter_count_b": 70,
    "creativity_score": 55,
    "logic_score": 85,
    "efficiency_score": 75,
    "model_family": "R1 Distilled",
    "name_within_family": "Llama 70B"
  },
  {
    "id": 131,
    "vendor_id": 9,
    "api_id": "deepseek/deepseek-r1-distill-qwen-14b",
    "slug": "deepseek-r1-distill-qwen-14b",
    "display_name": "DeepSeek: R1 Distill Qwen 14B",
    "display_order": 90,
    "description": "DeepSeek R1 Distill Qwen 14B is a distilled large language model based on [Qwen 2.5 14B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1).",
    "capabilities": [
      "reasoning"
    ],
    "context_length": 32768,
    "price_prompt_micro": 150000,
    "price_completion_micro": 150000,
    "price_tier": 1,
    "fallback_model_id": 212,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:27:44.431826+00:00",
    "parameter_count_b": 14,
    "personality_traits": [
      "Compact-Reasoning",
      "Cost-Saver"
    ],
    "professional_traits": [
      "Chain-of-thought reasoning"
    ],
    "best_for": [],
    "active_parameter_count_b": 14,
    "creativity_score": 45,
    "logic_score": 70,
    "efficiency_score": 95,
    "model_family": "R1 Distilled",
    "name_within_family": "DeepSeek Qwen 14B"
  },
  {
    "id": 144,
    "vendor_id": 8,
    "api_id": "deepcogito/cogito-v2.1-671b",
    "slug": "cogito-v2.1-671b",
    "display_name": "Deep Cogito: Cogito v2.1 671B",
    "display_order": 0,
    "description": "Cogito v2.1 671B MoE represents one of the strongest open models globally, matching performance of frontier closed and open models.",
    "capabilities": [
      "reasoning"
    ],
    "context_length": 128000,
    "price_prompt_micro": 1250000,
    "price_completion_micro": 1250000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Cogito",
    "name_within_family": "v2.1 671B"
  },
  {
    "id": 145,
    "vendor_id": 8,
    "api_id": "deepcogito/cogito-v2-preview-llama-405b",
    "slug": "cogito-v2-preview-llama-405b",
    "display_name": "Deep Cogito: Cogito V2 Preview Llama 405B",
    "display_order": 10,
    "description": "Cogito v2 405B is a dense hybrid reasoning model that combines direct answering capabilities with advanced self-reflection.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 32768,
    "price_prompt_micro": 3500000,
    "price_completion_micro": 3500000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Llama",
    "name_within_family": "Cogito V2 Preview Llama 405B"
  },
  {
    "id": 146,
    "vendor_id": 8,
    "api_id": "deepcogito/cogito-v2-preview-llama-70b",
    "slug": "cogito-v2-preview-llama-70b",
    "display_name": "Deep Cogito: Cogito V2 Preview Llama 70B",
    "display_order": 20,
    "description": "Cogito v2 70B is a dense hybrid reasoning model that combines direct answering capabilities with advanced self-reflection.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 32768,
    "price_prompt_micro": 880000,
    "price_completion_micro": 880000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Cogito",
    "name_within_family": "V2 Preview Llama 70B"
  },
  {
    "id": 149,
    "vendor_id": 19,
    "api_id": "moonshotai/kimi-k2-thinking",
    "slug": "kimi-k2-thinking",
    "display_name": "MoonshotAI: Kimi K2 Thinking",
    "display_order": 0,
    "description": "Kimi K2 Thinking is Moonshot AI’s most advanced open reasoning model to date, extending the K2 series into agentic, long-horizon reasoning.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 320000,
    "price_completion_micro": 480000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Kimi",
    "name_within_family": "K2 Thinking"
  },
  {
    "id": 150,
    "vendor_id": 19,
    "api_id": "moonshotai/kimi-k2-0905",
    "slug": "kimi-k2-0905",
    "display_name": "MoonshotAI: Kimi K2 0905",
    "display_order": 10,
    "description": "Kimi K2 0905 is the September update of [Kimi K2 0711](moonshotai/kimi-k2).",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 262144,
    "price_prompt_micro": 390000,
    "price_completion_micro": 1900000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Kimi",
    "name_within_family": "K2 0905"
  },
  {
    "id": 151,
    "vendor_id": 19,
    "api_id": "moonshotai/kimi-k2-0905:exacto",
    "slug": "kimi-k2-0905:exacto",
    "display_name": "MoonshotAI: Kimi K2 0905 (exacto)",
    "display_order": 20,
    "description": "Kimi K2 0905 is the September update of [Kimi K2 0711](moonshotai/kimi-k2).",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 262144,
    "price_prompt_micro": 600000,
    "price_completion_micro": 2500000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Kimi",
    "name_within_family": "K2 0905 (exacto)"
  },
  {
    "id": 152,
    "vendor_id": 19,
    "api_id": "moonshotai/kimi-k2",
    "slug": "kimi-k2",
    "display_name": "MoonshotAI: Kimi K2 0711",
    "display_order": 30,
    "description": "Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters with 32 billion active per forward pass.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 500000,
    "price_completion_micro": 2400000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Kimi",
    "name_within_family": "K2 0711"
  },
  {
    "id": 153,
    "vendor_id": 19,
    "api_id": "moonshotai/kimi-dev-72b",
    "slug": "kimi-dev-72b",
    "display_name": "MoonshotAI: Kimi Dev 72B",
    "display_order": 40,
    "description": "Kimi-Dev-72B is an open-source large language model fine-tuned for software engineering and issue resolution tasks.",
    "capabilities": [
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 290000,
    "price_completion_micro": 1150000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Kimi",
    "name_within_family": "Dev 72B"
  },
  {
    "id": 159,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-vl-235b-a22b-thinking",
    "slug": "qwen3-vl-235b-a22b-thinking",
    "display_name": "Qwen: Qwen3 VL 235B A22B Thinking",
    "display_order": 50,
    "description": "SOTA multimodal reasoning model for STEM and complex visual tasks",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 450000,
    "price_completion_micro": 3500000,
    "price_tier": 2,
    "fallback_model_id": 6,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:51:39.630645+00:00",
    "parameter_count_b": 235,
    "personality_traits": [
      "Precise",
      "Deep-Thinker",
      "Context-Heavy",
      "Analyst",
      "Visionary",
      "Stepwise"
    ],
    "professional_traits": [
      "Vision",
      "video (hours-long)",
      "visual agent",
      "GUI operation",
      "spatial reasoning",
      "OCR",
      "chart/diagram analysis",
      "visual coding"
    ],
    "best_for": [
      "STEM visual reasoning",
      "complex document analysis",
      "visual coding",
      "scientific image analysis",
      "embodied AI applications"
    ],
    "active_parameter_count_b": 22,
    "creativity_score": 65,
    "logic_score": 90,
    "efficiency_score": 70,
    "model_family": "Qwen3 VL",
    "name_within_family": "3 VL 235B A22B Thinking"
  },
  {
    "id": 160,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-vl-235b-a22b-instruct",
    "slug": "qwen3-vl-235b-a22b-instruct",
    "display_name": "Qwen3 VL 235B A22B Instruct",
    "display_order": 60,
    "description": "Flagship vision-language for general perception and agent tasks",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 262144,
    "price_prompt_micro": 120000,
    "price_completion_micro": 560000,
    "price_tier": 1,
    "fallback_model_id": 189,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:56:07.66198+00:00",
    "parameter_count_b": 235,
    "personality_traits": [
      "Precise",
      "Context-Heavy",
      "Tool-Seeker",
      "Analyst",
      "Fast-Twitch"
    ],
    "professional_traits": [
      "Vision",
      "video",
      "visual agent",
      "tool use",
      "GUI interaction",
      "document parsing",
      "object grounding"
    ],
    "best_for": [
      "Document parsing",
      "VQA",
      "chart extraction",
      "multilingual OCR",
      "video analysis",
      "GUI automation",
      "general multimodal tasks"
    ],
    "active_parameter_count_b": 22,
    "creativity_score": 60,
    "logic_score": 80,
    "efficiency_score": 80,
    "model_family": "Qwen3 VL",
    "name_within_family": "3 VL 235B A22B Instruct"
  },
  {
    "id": 9,
    "vendor_id": 36,
    "api_id": "z-ai/glm-4.5v",
    "slug": "glm-4.5v",
    "display_name": "GLM 4.5V",
    "display_order": 40,
    "description": "Open-source vision-language model excelling at document and GUI understanding",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 65536,
    "price_prompt_micro": 600000,
    "price_completion_micro": 1800000,
    "price_tier": 2,
    "fallback_model_id": 184,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:34:58.397455+00:00",
    "parameter_count_b": 106,
    "personality_traits": [
      "Precise",
      "Didactic",
      "Context-Heavy",
      "Tool-Seeker",
      "Analyst",
      "Cautious",
      "Stepwise"
    ],
    "professional_traits": [
      "Vision understanding",
      "video processing",
      "GUI automation",
      "document analysis",
      "chart parsing",
      "image grounding",
      "thinking mode toggle"
    ],
    "best_for": [
      "Image/video reasoning",
      "GUI agent tasks",
      "document parsing",
      "chart analysis",
      "frontend code replication",
      "long document interpretation"
    ],
    "active_parameter_count_b": 12,
    "creativity_score": 55,
    "logic_score": 75,
    "efficiency_score": 80,
    "model_family": "GLM",
    "name_within_family": "4.5V"
  },
  {
    "id": 135,
    "vendor_id": 3,
    "api_id": "anthropic/claude-opus-4.5",
    "slug": "claude-opus-4.5",
    "display_name": "Anthropic: Claude Opus 4.5",
    "display_order": 0,
    "description": "Anthropic's most intelligent model - #2 globally, best for coding/agents",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 200000,
    "price_prompt_micro": 5000000,
    "price_completion_micro": 25000000,
    "price_tier": 3,
    "fallback_model_id": 14,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:08:58.19908+00:00",
    "parameter_count_b": 2200,
    "personality_traits": [
      "Most-Intelligent",
      "Agentic-Master",
      "Code-King",
      "Safety-Leader",
      "Self-Improving"
    ],
    "professional_traits": [
      "extended thinking",
      "self-improving"
    ],
    "best_for": [
      "complex coding",
      "research",
      "high-stakes tasks",
      "Enterprise workflows"
    ],
    "active_parameter_count_b": 80,
    "creativity_score": 85,
    "logic_score": 95,
    "efficiency_score": 80,
    "model_family": "Claude",
    "name_within_family": "Opus 4.5"
  },
  {
    "id": 20,
    "vendor_id": 11,
    "api_id": "google/gemini-2.5-flash",
    "slug": "gemini-2.5-flash",
    "display_name": "Gemini 2.5 Flash",
    "display_order": 80,
    "description": "First Flash model with thinking - great balance of price/performance",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 1048576,
    "price_prompt_micro": 300000,
    "price_completion_micro": 2500000,
    "price_tier": 2,
    "fallback_model_id": 138,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:35:30.94851+00:00",
    "parameter_count_b": 200,
    "personality_traits": [
      "Balanced",
      "Thinking-Enabled",
      "Value-Tier"
    ],
    "professional_traits": [
      "search grounding",
      "code execution",
      "thinking mode"
    ],
    "best_for": [
      "Cost-conscious production",
      "balanced workloads",
      "thinking-enabled tasks"
    ],
    "active_parameter_count_b": 6,
    "creativity_score": 70,
    "logic_score": 80,
    "efficiency_score": 90,
    "model_family": "Gemini",
    "name_within_family": "2.5 Flash"
  },
  {
    "id": 63,
    "vendor_id": 24,
    "api_id": "openai/o3",
    "slug": "o3",
    "display_name": "o3",
    "display_order": 250,
    "description": "OpenAI's most capable reasoning model with full tool access",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 200000,
    "price_prompt_micro": 2000000,
    "price_completion_micro": 8000000,
    "price_tier": 3,
    "fallback_model_id": 143,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:27:58.300055+00:00",
    "parameter_count_b": 3,
    "personality_traits": [
      "Deep-Thinker",
      "Precise",
      "Stepwise",
      "Tool-Master",
      "Visual-Reasoner"
    ],
    "professional_traits": [
      "Vision",
      "image generation (via tool)",
      "web search",
      "Python execution"
    ],
    "best_for": [
      "Complex multi-step reasoning",
      "scientific research",
      "hypothesis generation",
      "visual analysis"
    ],
    "active_parameter_count_b": 200,
    "creativity_score": 55,
    "logic_score": 96,
    "efficiency_score": 65,
    "model_family": "o",
    "name_within_family": "o3"
  },
  {
    "id": 120,
    "vendor_id": 4,
    "api_id": "arcee-ai/trinity-mini:free",
    "slug": "trinity-mini:free",
    "display_name": "Arcee AI: Trinity Mini (free)",
    "display_order": 0,
    "description": "Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts language model featuring 128 experts with 8 active per token.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 0,
    "price_completion_micro": 0,
    "price_tier": 0,
    "fallback_model_id": 26,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 26,
    "personality_traits": [
      "Precise",
      "Tool-Seeker",
      "Stepwise",
      "Fast-Twitch",
      "Assertive"
    ],
    "professional_traits": [],
    "best_for": [],
    "active_parameter_count_b": 3,
    "creativity_score": 75,
    "logic_score": 85,
    "efficiency_score": 95,
    "model_family": "Trinity",
    "name_within_family": "Mini (free)"
  },
  {
    "id": 11,
    "vendor_id": 36,
    "api_id": "z-ai/glm-4.5-air",
    "slug": "glm-4.5-air",
    "display_name": "GLM 4.5 Air",
    "display_order": 60,
    "description": "Compact, cost-efficient variant of GLM-4.5 for high-volume deployments\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 50000,
    "price_completion_micro": 220000,
    "price_tier": 1,
    "fallback_model_id": 120,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:38:27.404472+00:00",
    "parameter_count_b": 106,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Fast-Twitch",
      "Tool-Seeker",
      "Stepwise",
      "Cost-Saver"
    ],
    "professional_traits": [
      "cost-efficient inference"
    ],
    "best_for": [
      "Cost-sensitive",
      "resource-constrained"
    ],
    "active_parameter_count_b": 12,
    "creativity_score": 45,
    "logic_score": 75,
    "efficiency_score": 95,
    "model_family": "GLM",
    "name_within_family": "4.5 Air"
  },
  {
    "id": 201,
    "vendor_id": 13,
    "api_id": "inception/mercury-coder",
    "slug": "mercury-coder",
    "display_name": "Mercury Coder",
    "display_order": 10,
    "description": "World's first commercial diffusion LLM - 10x faster than autoregressive models",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 128000,
    "price_prompt_micro": 250000,
    "price_completion_micro": 1000000,
    "price_tier": 2,
    "fallback_model_id": 140,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 8,
    "personality_traits": [
      "Fast-Twitch",
      "Precise",
      "Concise",
      "Deterministic-Lean",
      "Exploit-Focused"
    ],
    "professional_traits": [
      "Fill-in-the-middle (FIM)",
      "Apply-Edit",
      "code autocomplete",
      "Next-Edit"
    ],
    "best_for": [
      "Code generation",
      "code completion",
      "Apply-Edit workflows",
      "latency-critical coding"
    ],
    "active_parameter_count_b": 8,
    "creativity_score": 65,
    "logic_score": 80,
    "efficiency_score": 100,
    "model_family": "Mercury",
    "name_within_family": "Coder"
  },
  {
    "id": 19,
    "vendor_id": 11,
    "api_id": "google/gemini-2.5-flash-lite",
    "slug": "gemini-2.5-flash-lite",
    "display_name": "Gemini 2.5 Flash Lite",
    "display_order": 70,
    "description": "Lowest cost 2.5 model - optimized for high throughput",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 1048576,
    "price_prompt_micro": 100000,
    "price_completion_micro": 400000,
    "price_tier": 1,
    "fallback_model_id": 67,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:38:03.34638+00:00",
    "parameter_count_b": 100,
    "personality_traits": [
      "Budget-King",
      "High-Throughput",
      "Low-Latency"
    ],
    "professional_traits": [
      "search grounding",
      "code execution"
    ],
    "best_for": [
      "Classification",
      "summarization at scale",
      "high-volume simple tasks"
    ],
    "active_parameter_count_b": 3,
    "creativity_score": 60,
    "logic_score": 70,
    "efficiency_score": 100,
    "model_family": "Gemini",
    "name_within_family": "2.5 Flash Lite"
  },
  {
    "id": 40,
    "vendor_id": 24,
    "api_id": "openai/gpt-5.2",
    "slug": "gpt-5.2",
    "display_name": "GPT-5.2",
    "display_order": 20,
    "description": "OpenAI's flagship model - SOTA knowledge work and reasoning",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 400000,
    "price_prompt_micro": 1750000,
    "price_completion_micro": 14000000,
    "price_tier": 3,
    "fallback_model_id": 135,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:09:00.266112+00:00",
    "parameter_count_b": 2500,
    "personality_traits": [
      "Analyst",
      "Context-Heavy",
      "Tool-Seeker",
      "Enterprise-Grade",
      "Knowledge-Worker"
    ],
    "professional_traits": [
      "Vision",
      "tool calling",
      "structured outputs",
      "spreadsheets",
      "presentations",
      "extended reasoning (xhigh)",
      "compaction"
    ],
    "best_for": [
      "Enterprise knowledge work",
      "complex analysis",
      "professional document generation"
    ],
    "active_parameter_count_b": 150,
    "creativity_score": 70,
    "logic_score": 95,
    "efficiency_score": 70,
    "model_family": "GPT-5",
    "name_within_family": "5.2"
  },
  {
    "id": 181,
    "vendor_id": 27,
    "api_id": "qwen/qwq-32b",
    "slug": "qwq-32b",
    "display_name": "QwQ 32B",
    "display_order": 270,
    "description": "Compact reasoning powerhouse rivaling DeepSeek-R1 at 1/20th size\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 32768,
    "price_prompt_micro": 150000,
    "price_completion_micro": 400000,
    "price_tier": 1,
    "fallback_model_id": 177,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:02:35.536986+00:00",
    "parameter_count_b": 32,
    "personality_traits": [
      "Precise",
      "Deep-Thinker",
      "Stepwise",
      "Self-Correcting",
      "Analyst"
    ],
    "professional_traits": [
      "Chain-of-thought reasoning",
      "multilingual (29 languages)"
    ],
    "best_for": [
      "Math reasoning",
      "coding tasks"
    ],
    "active_parameter_count_b": 32,
    "creativity_score": 50,
    "logic_score": 90,
    "efficiency_score": 85,
    "model_family": "QwQ",
    "name_within_family": "32B"
  },
  {
    "id": 3,
    "vendor_id": 17,
    "api_id": "minimax/minimax-m2.1",
    "slug": "minimax-m2.1",
    "display_name": "MiniMax M2.1",
    "display_order": 0,
    "description": " #1 open-source model globally with exceptional multi-language coding",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 196608,
    "price_prompt_micro": 120000,
    "price_completion_micro": 480000,
    "price_tier": 1,
    "fallback_model_id": 196,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 230,
    "personality_traits": [
      "Precise",
      "Deep-Thinker",
      "Tool-Seeker",
      "Self-Correcting",
      "Cost-Saver"
    ],
    "professional_traits": [
      "browser control",
      "code execution"
    ],
    "best_for": [
      "Multi-language coding"
    ],
    "active_parameter_count_b": 10,
    "creativity_score": 80,
    "logic_score": 85,
    "efficiency_score": 95,
    "model_family": "MiniMax",
    "name_within_family": "M2.1"
  },
  {
    "id": 35,
    "vendor_id": 23,
    "api_id": "nvidia/nemotron-3-nano-30b-a3b",
    "slug": "nemotron-3-nano-30b-a3b",
    "display_name": "Nemotron 3 Nano 30B A3B",
    "display_order": 0,
    "description": "NVIDIA's flagship open model: hybrid architecture achieves 3.3x throughput of comparable models",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 60000,
    "price_completion_micro": 240000,
    "price_tier": 1,
    "fallback_model_id": 188,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 32,
    "personality_traits": [
      "Precise",
      "Tool-Seeker",
      "Stepwise",
      "Long-Horizon",
      "Fast-Twitch"
    ],
    "professional_traits": [
      "reasoning",
      "budget control"
    ],
    "best_for": [
      "long-context processing"
    ],
    "active_parameter_count_b": 3,
    "creativity_score": 75,
    "logic_score": 90,
    "efficiency_score": 100,
    "model_family": "Nemotron",
    "name_within_family": "3 Nano 30B A3B"
  },
  {
    "id": 72,
    "vendor_id": 24,
    "api_id": "openai/o3-mini",
    "slug": "o3-mini",
    "display_name": "o3 Mini",
    "display_order": 340,
    "description": "OpenAI o3-mini is a cost-efficient language model optimized for STEM reasoning tasks, particularly excelling in science, mathematics, and coding.\n\nThis model supports the `reasoning_effort` parameter, which can be set to \"high\", \"medium\", or \"low\" to control the thinking time of the model.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 200000,
    "price_prompt_micro": 1100000,
    "price_completion_micro": 4400000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T16:53:58.535853+00:00",
    "parameter_count_b": 100,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "o",
    "name_within_family": "3 Mini"
  },
  {
    "id": 184,
    "vendor_id": 27,
    "api_id": "qwen/qwen-2.5-72b-instruct",
    "slug": "qwen-2.5-72b-instruct",
    "display_name": "Qwen2.5 72B Instruct",
    "display_order": 300,
    "description": "Previous-gen vision flagship, battle-tested and stable",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 32768,
    "price_prompt_micro": 120000,
    "price_completion_micro": 390000,
    "price_tier": 1,
    "fallback_model_id": 159,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:07:53.959319+00:00",
    "parameter_count_b": 72,
    "personality_traits": [
      "Precise",
      "Context-Heavy",
      "Analyst",
      "Tool-Seeker"
    ],
    "professional_traits": [
      "Vision",
      "video",
      "OCR",
      "visual agent",
      "document parsing",
      "object grounding"
    ],
    "best_for": [
      "document parsing",
      "video analysis",
      "GUI agent tasks"
    ],
    "active_parameter_count_b": 72,
    "creativity_score": 55,
    "logic_score": 75,
    "efficiency_score": 70,
    "model_family": "Qwen 2.5",
    "name_within_family": "72B Instruct"
  },
  {
    "id": 187,
    "vendor_id": 31,
    "api_id": "thedrummer/rocinante-12b",
    "slug": "rocinante-12b",
    "display_name": "TheDrummer: Rocinante 12B",
    "display_order": 20,
    "description": "Rocinante 12B is designed for engaging storytelling and rich prose.\n\nEarly testers have reported:\n- Expanded vocabulary with unique and expressive word choices\n- Enhanced creativity for vivid narratives\n- Adventure-filled and captivating stories",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 32768,
    "price_prompt_micro": 170000,
    "price_completion_micro": 430000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T16:53:58.535853+00:00",
    "parameter_count_b": 12,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Rocinante",
    "name_within_family": "12B"
  },
  {
    "id": 5,
    "vendor_id": 36,
    "api_id": "z-ai/glm-4.7",
    "slug": "glm-4.7",
    "display_name": "GLM 4.7",
    "display_order": 0,
    "description": "Flagship open-source coding powerhouse with state-of-the-art agentic capabilities\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 202752,
    "price_prompt_micro": 160000,
    "price_completion_micro": 800000,
    "price_tier": 1,
    "fallback_model_id": 170,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:29:57.350395+00:00",
    "parameter_count_b": 355,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Stepwise",
      "Tool-Seeker",
      "Long-Horizon",
      "Context-Heavy",
      "Assertive",
      "Formal",
      "Exploit-Focused",
      "Self-Correcting"
    ],
    "professional_traits": [
      "mathematical reasoning",
      "frontend development",
      "search"
    ],
    "best_for": [
      "multi-file software engineering",
      "long-horizon development workflows",
      "mathematical reasoning",
      "Claude Code/Cline/Roo Code integration"
    ],
    "active_parameter_count_b": 32,
    "creativity_score": 55,
    "logic_score": 90,
    "efficiency_score": 95,
    "model_family": "GLM",
    "name_within_family": "4.7"
  },
  {
    "id": 6,
    "vendor_id": 36,
    "api_id": "z-ai/glm-4.6v",
    "slug": "glm-4.6v",
    "display_name": "GLM 4.6V",
    "display_order": 10,
    "description": "Vision-language model with native multimodal function calling for agentic workflows\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 300000,
    "price_completion_micro": 900000,
    "price_tier": 2,
    "fallback_model_id": 9,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:31:14.218379+00:00",
    "parameter_count_b": 106,
    "personality_traits": [
      "Precise",
      "Context-Heavy",
      "Tool-Seeker",
      "Analyst",
      "Stepwise",
      "Long-Horizon",
      "Formal"
    ],
    "professional_traits": [
      "Vision understanding",
      "video processing",
      "document parsing",
      "chart analysis",
      "GUI agent tasks",
      "image grounding",
      "frontend code generation"
    ],
    "best_for": [
      "Document analysis",
      "multimodal agents",
      "visual web search",
      "frontend UI replication",
      "rich-text content creation",
      "financial report analysis",
      "video understanding"
    ],
    "active_parameter_count_b": 12,
    "creativity_score": 60,
    "logic_score": 80,
    "efficiency_score": 85,
    "model_family": "GLM",
    "name_within_family": "4.6V"
  },
  {
    "id": 7,
    "vendor_id": 36,
    "api_id": "z-ai/glm-4.6",
    "slug": "glm-4.6",
    "display_name": "GLM 4.6",
    "display_order": 20,
    "description": "First frontier-scale fully open MIT-licensed model with near-Claude Sonnet 4 performance\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 202752,
    "price_prompt_micro": 350000,
    "price_completion_micro": 1500000,
    "price_tier": 2,
    "fallback_model_id": 10,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:32:56.038152+00:00",
    "parameter_count_b": 355,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Tool-Seeker",
      "Stepwise",
      "Long-Horizon",
      "Context-Heavy",
      "Assertive",
      "Formal"
    ],
    "professional_traits": [
      "long-context reasoning",
      "code generation",
      "frontend development",
      "search agents"
    ],
    "best_for": [
      "long-context processing",
      "Chinese-English bilingual tasks",
      "code generation"
    ],
    "active_parameter_count_b": 32,
    "creativity_score": 55,
    "logic_score": 85,
    "efficiency_score": 90,
    "model_family": "GLM",
    "name_within_family": "4.6"
  },
  {
    "id": 10,
    "vendor_id": 36,
    "api_id": "z-ai/glm-4.5",
    "slug": "glm-4.5",
    "display_name": "GLM 4.5",
    "display_order": 50,
    "description": "Unified reasoning, coding, and agent foundation model with hybrid thinking modes\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 350000,
    "price_completion_micro": 1550000,
    "price_tier": 2,
    "fallback_model_id": 172,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:36:34.875659+00:00",
    "parameter_count_b": 355,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Tool-Seeker",
      "Stepwise",
      "Long-Horizon",
      "Assertive",
      "Formal",
      "Conservative-Planner"
    ],
    "professional_traits": [
      "code generation"
    ],
    "best_for": [
      "code generation",
      "complex reasoning tasks"
    ],
    "active_parameter_count_b": 32,
    "creativity_score": 50,
    "logic_score": 85,
    "efficiency_score": 85,
    "model_family": "GLM",
    "name_within_family": "4.5"
  },
  {
    "id": 183,
    "vendor_id": 27,
    "api_id": "qwen/qwen-2.5-coder-32b-instruct",
    "slug": "qwen-2.5-coder-32b-instruct",
    "display_name": "Qwen2.5 Coder 32B Instruct",
    "display_order": 290,
    "description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen).",
    "capabilities": [],
    "context_length": 32768,
    "price_prompt_micro": 30000,
    "price_completion_micro": 110000,
    "price_tier": 1,
    "fallback_model_id": 201,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 32,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Qwen 2.5",
    "name_within_family": "Coder 32B Instruct"
  },
  {
    "id": 170,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-coder",
    "slug": "qwen3-coder",
    "display_name": "Qwen: Qwen3 Coder 480B A35B",
    "display_order": 160,
    "description": "Most agentic open-source coding model, comparable to Claude Sonnet 4",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 220000,
    "price_completion_micro": 950000,
    "price_tier": 2,
    "fallback_model_id": 91,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:44:51.453647+00:00",
    "parameter_count_b": 480,
    "personality_traits": [
      "Precise",
      "Tool-Seeker",
      "Stepwise",
      "Exploit-Focused",
      "Long-Horizon",
      "Self-Correcting",
      "Fast-Twitch"
    ],
    "professional_traits": [
      "Code generation",
      "multi-turn coding sessions",
      "TypeScript/Python/Java/Rust/C++/Go"
    ],
    "best_for": [
      "Agentic coding workflows",
      "repository-scale engineering",
      "complex debugging",
      "automated PR workflows"
    ],
    "active_parameter_count_b": 35,
    "creativity_score": 45,
    "logic_score": 90,
    "efficiency_score": 85,
    "model_family": "Qwen3 Coder",
    "name_within_family": "3 Coder 480B A35B"
  },
  {
    "id": 169,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-235b-a22b-thinking-2507",
    "slug": "qwen3-235b-a22b-thinking-2507",
    "display_name": "Qwen: Qwen3 235B A22B Thinking 2507",
    "display_order": 150,
    "description": "SOTA open-source reasoning model, rivals DeepSeek-R1 and o1\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 110000,
    "price_completion_micro": 600000,
    "price_tier": 1,
    "fallback_model_id": 60,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:46:18.50475+00:00",
    "parameter_count_b": 235,
    "personality_traits": [
      "Precise",
      "Deep-Thinker",
      "Analyst",
      "Visionary",
      "Stepwise",
      "Self-Correcting",
      "Long-Horizon"
    ],
    "professional_traits": [
      "Extended reasoning traces",
      "thinking mode",
      "119 language support"
    ],
    "best_for": [
      "Complex multi-step reasoning",
      "mathematical proofs",
      "scientific analysis",
      "research tasks requiring deep thought"
    ],
    "active_parameter_count_b": 22,
    "creativity_score": 65,
    "logic_score": 95,
    "efficiency_score": 75,
    "model_family": "Qwen3",
    "name_within_family": "3 235B A22B Thinking 2507"
  },
  {
    "id": 177,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-32b",
    "slug": "qwen3-32b",
    "display_name": "Qwen: Qwen3 32B",
    "display_order": 230,
    "description": "Best dense model, ideal for fine-tuning and local deployment",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 40960,
    "price_prompt_micro": 80000,
    "price_completion_micro": 240000,
    "price_tier": 1,
    "fallback_model_id": 166,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:06:31.791887+00:00",
    "parameter_count_b": 32,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Assertive",
      "Stepwise",
      "Context-Heavy"
    ],
    "professional_traits": [],
    "best_for": [],
    "active_parameter_count_b": 32,
    "creativity_score": 55,
    "logic_score": 80,
    "efficiency_score": 75,
    "model_family": "Qwen3",
    "name_within_family": "3 32B"
  },
  {
    "id": 140,
    "vendor_id": 35,
    "api_id": "x-ai/grok-code-fast-1",
    "slug": "grok-code-fast-1",
    "display_name": "Grok Code Fast 1",
    "display_order": 20,
    "description": "Purpose-built speedster for agentic coding workflows",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 256000,
    "price_prompt_micro": 200000,
    "price_completion_micro": 1500000,
    "price_tier": 2,
    "fallback_model_id": 91,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:13:42.997636+00:00",
    "parameter_count_b": 314,
    "personality_traits": [
      "Precise",
      "Fast-Twitch",
      "Stepwise",
      "Tool-Seeker",
      "Exploit-Focused"
    ],
    "professional_traits": [
      "Fast inference",
      "code generation",
      "debugging",
      "reasoning traces"
    ],
    "best_for": [
      "rapid code iteration",
      "bug fixes",
      "codebase Q&A",
      "zero-to-one projects",
      "developer-in-the-loop workflows"
    ],
    "active_parameter_count_b": 25,
    "creativity_score": 40,
    "logic_score": 75,
    "efficiency_score": 90,
    "model_family": "Grok",
    "name_within_family": "Code Fast 1"
  },
  {
    "id": 172,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-235b-a22b-2507",
    "slug": "qwen3-235b-a22b-2507",
    "display_name": "Qwen3 235B A22B Instruct 2507",
    "display_order": 180,
    "description": "Flagship general-purpose model with improved instruction following",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 262144,
    "price_prompt_micro": 71000,
    "price_completion_micro": 463000,
    "price_tier": 1,
    "fallback_model_id": 96,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T06:49:25.207655+00:00",
    "parameter_count_b": 235,
    "personality_traits": [
      "Precise",
      "Analyst",
      "Tool-Seeker",
      "Assertive",
      "Context-Heavy",
      "Formal"
    ],
    "professional_traits": [
      "Fast inference",
      "119 languages"
    ],
    "best_for": [
      "General chat",
      "instruction following",
      "creative writing",
      "multilingual tasks",
      "enterprise deployments where speed matters"
    ],
    "active_parameter_count_b": 22,
    "creativity_score": 60,
    "logic_score": 85,
    "efficiency_score": 85,
    "model_family": "Qwen3",
    "name_within_family": "3 235B A22B Instruct 2507"
  },
  {
    "id": 166,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-30b-a3b-thinking-2507",
    "slug": "qwen3-30b-a3b-thinking-2507",
    "display_name": "Qwen3 30B A3B Thinking 2507",
    "display_order": 120,
    "description": "Sweet-spot MoE that outperforms QwQ-32B with fewer active params\n",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 32768,
    "price_prompt_micro": 51000,
    "price_completion_micro": 340000,
    "price_tier": 1,
    "fallback_model_id": 192,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:05:15.255981+00:00",
    "parameter_count_b": 30,
    "personality_traits": [
      "Precise",
      "Fast-Twitch",
      "Cost-Saver",
      "Analyst",
      "Stepwise"
    ],
    "professional_traits": [
      "119 languages"
    ],
    "best_for": [
      "Cost-sensitive production",
      "general reasoning at scale"
    ],
    "active_parameter_count_b": 3,
    "creativity_score": 50,
    "logic_score": 75,
    "efficiency_score": 95,
    "model_family": "Qwen3",
    "name_within_family": "3 30B A3B Thinking (2507)"
  },
  {
    "id": 142,
    "vendor_id": 35,
    "api_id": "x-ai/grok-3-mini",
    "slug": "grok-3-mini",
    "display_name": "Grok 3 Mini",
    "display_order": 40,
    "description": "A lightweight model that thinks before responding.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 300000,
    "price_completion_micro": 500000,
    "price_tier": 1,
    "fallback_model_id": 166,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:18:37.057633+00:00",
    "parameter_count_b": 300,
    "personality_traits": [
      "Precise",
      "Stepwise",
      "Fast-Twitch",
      "Cost-Saver",
      "Analyst",
      "Obedient"
    ],
    "professional_traits": [
      "ransparent reasoning",
      "adjustable reasoning effort"
    ],
    "best_for": [
      "Logic-based tasks",
      "STEM problems",
      "math competitions",
      "rapid reasoning",
      "cost-efficient deployments",
      "educational applications"
    ],
    "active_parameter_count_b": 20,
    "creativity_score": 40,
    "logic_score": 75,
    "efficiency_score": 90,
    "model_family": "Grok",
    "name_within_family": "3 Mini"
  },
  {
    "id": 143,
    "vendor_id": 35,
    "api_id": "x-ai/grok-3",
    "slug": "grok-3",
    "display_name": "Grok 3",
    "display_order": 50,
    "description": "First frontier reasoning model from xAI with \"Think\" capability",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 131072,
    "price_prompt_micro": 3000000,
    "price_completion_micro": 15000000,
    "price_tier": 3,
    "fallback_model_id": 128,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T07:20:25.612257+00:00",
    "parameter_count_b": 1200,
    "personality_traits": [
      "Precise",
      "Deep-Thinker",
      "Analyst",
      "Visionary",
      "Stepwise",
      "Self-Correcting",
      "backtracking",
      "multi-step problem solving"
    ],
    "professional_traits": [
      "Chain-of-thought reasoning"
    ],
    "best_for": [
      "Complex reasoning",
      "mathematical problem-solving",
      "code generation",
      "research tasks",
      "problems requiring iterative refinement"
    ],
    "active_parameter_count_b": 100,
    "creativity_score": 55,
    "logic_score": 85,
    "efficiency_score": 50,
    "model_family": "Grok",
    "name_within_family": "3"
  },
  {
    "id": 168,
    "vendor_id": 27,
    "api_id": "qwen/qwen3-30b-a3b-instruct-2507",
    "slug": "qwen3-30b-a3b-instruct-2507",
    "display_name": "Qwen: Qwen3 30B A3B Instruct 2507",
    "display_order": 140,
    "description": "Qwen3-30B-A3B-Instruct-2507 is a 30.5B-parameter mixture-of-experts language model from Qwen, with 3.3B active parameters per inference.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 262144,
    "price_prompt_micro": 80000,
    "price_completion_micro": 330000,
    "price_tier": 1,
    "fallback_model_id": 166,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Qwen3",
    "name_within_family": "3 30B A3B Instruct 2507"
  },
  {
    "id": 191,
    "vendor_id": 22,
    "api_id": "nousresearch/hermes-4-70b",
    "slug": "hermes-4-70b",
    "display_name": "Hermes 4 70B",
    "display_order": 0,
    "description": "Frontier hybrid-reasoning model with user alignment",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 131072,
    "price_prompt_micro": 110000,
    "price_completion_micro": 380000,
    "price_tier": 1,
    "fallback_model_id": 193,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 70,
    "personality_traits": [
      "User-Aligned",
      "Hybrid-Reasoner",
      "Non-Sycophantic",
      "Steerable",
      "Creative",
      "Uncensored",
      "Neutral",
      "Anti-Lecture",
      "Humanistic",
      "Transparent-Thinker"
    ],
    "professional_traits": [
      "Hybrid Reasoning Mode"
    ],
    "best_for": [
      "Complex reasoning with transparent thought processes",
      "math/code/STEM problems",
      "creative writing and roleplay",
      "tasks requiring schema-adherent outputs",
      "users who want models that follow their instructions without moralizing"
    ],
    "active_parameter_count_b": 70,
    "creativity_score": 75,
    "logic_score": 75,
    "efficiency_score": 85,
    "model_family": "Hermes",
    "name_within_family": "4 70B"
  },
  {
    "id": 185,
    "vendor_id": 31,
    "api_id": "thedrummer/cydonia-24b-v4.1",
    "slug": "cydonia-24b-v4.1",
    "display_name": "TheDrummer: Cydonia 24B V4.1",
    "display_order": 0,
    "description": "Uncensored and creative writing model based on Mistral Small 3.2 24B with good recall, prompt adherence, and intelligence.",
    "capabilities": [],
    "context_length": 131072,
    "price_prompt_micro": 300000,
    "price_completion_micro": 500000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Cydonia",
    "name_within_family": "24B V4.1"
  },
  {
    "id": 186,
    "vendor_id": 31,
    "api_id": "thedrummer/unslopnemo-12b",
    "slug": "unslopnemo-12b",
    "display_name": "TheDrummer: UnslopNemo 12B",
    "display_order": 10,
    "description": "UnslopNemo v4.1 is the latest addition from the creator of Rocinante, designed for adventure writing and role-play scenarios.",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 32768,
    "price_prompt_micro": 400000,
    "price_completion_micro": 400000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "UnslopNemo",
    "name_within_family": "12B"
  },
  {
    "id": 190,
    "vendor_id": 29,
    "api_id": "stepfun-ai/step3",
    "slug": "step3",
    "display_name": "StepFun: Step3",
    "display_order": 0,
    "description": "Step3 is a cutting-edge multimodal reasoning model—built on a Mixture-of-Experts architecture with 321B total parameters and 38B active.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 65536,
    "price_prompt_micro": 570000,
    "price_completion_micro": 1420000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Step",
    "name_within_family": "3"
  },
  {
    "id": 197,
    "vendor_id": 32,
    "api_id": "tngtech/deepseek-r1t2-chimera",
    "slug": "deepseek-r1t2-chimera",
    "display_name": "TNG: DeepSeek R1T2 Chimera",
    "display_order": 0,
    "description": "DeepSeek-TNG-R1T2-Chimera is the second-generation Chimera model from TNG Tech.",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 163840,
    "price_prompt_micro": 250000,
    "price_completion_micro": 850000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "DeepSeek R1",
    "name_within_family": "R1T2 Chimera"
  },
  {
    "id": 198,
    "vendor_id": 32,
    "api_id": "tngtech/deepseek-r1t-chimera",
    "slug": "deepseek-r1t-chimera",
    "display_name": "TNG: DeepSeek R1T Chimera",
    "display_order": 10,
    "description": "DeepSeek-R1T-Chimera is created by merging DeepSeek-R1 and DeepSeek-V3 (0324), combining the reasoning capabilities of R1 with the token efficiency improvements of V3.",
    "capabilities": [
      "reasoning"
    ],
    "context_length": 163840,
    "price_prompt_micro": 300000,
    "price_completion_micro": 1200000,
    "price_tier": 2,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "DeepSeek R1",
    "name_within_family": "R1T Chimera"
  },
  {
    "id": 192,
    "vendor_id": 22,
    "api_id": "nousresearch/deephermes-3-mistral-24b-preview",
    "slug": "deephermes-3-mistral-24b-preview",
    "display_name": " DeepHermes 3 Mistral 24B Preview",
    "display_order": 10,
    "description": "Deep-thinking reasoning model with dual-mode operation",
    "capabilities": [
      "tools",
      "tool_choice",
      "reasoning"
    ],
    "context_length": 32768,
    "price_prompt_micro": 20000,
    "price_completion_micro": 100000,
    "price_tier": 1,
    "fallback_model_id": 102,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-16T17:16:03.93211+00:00",
    "parameter_count_b": 24,
    "personality_traits": [
      "Deep-Thinker",
      "Dual-Mode",
      "Analytical",
      "Methodical",
      "Deliberate",
      "Systematic",
      "Problem-Solver"
    ],
    "professional_traits": [
      "Deep Thinking Mode"
    ],
    "best_for": [
      "Complex mathematical problem-solving",
      "analytical tasks requiring extended deliberation"
    ],
    "active_parameter_count_b": 24,
    "creativity_score": 60,
    "logic_score": 80,
    "efficiency_score": 75,
    "model_family": "Hermes",
    "name_within_family": "DeepHermes 3 Mistral 24B Preview"
  },
  {
    "id": 215,
    "vendor_id": 28,
    "api_id": "sao10k/l3-lunaris-8b",
    "slug": "l3-lunaris-8b",
    "display_name": "Llama 3 8B Lunaris",
    "display_order": 20,
    "description": "Strategic 5-model merge balancing creativity and logic",
    "capabilities": [],
    "context_length": 8192,
    "price_prompt_micro": 40000,
    "price_completion_micro": 50000,
    "price_tier": 1,
    "fallback_model_id": 218,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:03:21.698778+00:00",
    "parameter_count_b": 8,
    "personality_traits": [
      "Balanced",
      "Character-Focused",
      "Contextual",
      "Versatile",
      "Merged",
      "Creative-Logical",
      "Efficient",
      "Persona-Maintainer",
      "Emotionally-Deep",
      "Generalist"
    ],
    "professional_traits": [
      "Character Embodiment",
      "Emotional Depth",
      "Contextual Awareness",
      "Balanced Creativity-Logic"
    ],
    "best_for": [
      "Interactive roleplay on a budget",
      "character-driven storytelling",
      "creative text generation",
      "conversational AI",
      "consumer hardware deployment"
    ],
    "active_parameter_count_b": 8,
    "creativity_score": 75,
    "logic_score": 60,
    "efficiency_score": 85,
    "model_family": "Llama",
    "name_within_family": "3 8B Lunaris"
  },
  {
    "id": 202,
    "vendor_id": 15,
    "api_id": "meta-llama/llama-4-maverick",
    "slug": "llama-4-maverick",
    "display_name": "Llama 4 Maverick",
    "display_order": 0,
    "description": "Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal language model from Meta, built on a mixture-of-experts (MoE) architecture with 128 experts and 17 billion active parameters per forward pass (400B total).",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 1048576,
    "price_prompt_micro": 150000,
    "price_completion_micro": 600000,
    "price_tier": 1,
    "fallback_model_id": 206,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:41:31.157636+00:00",
    "parameter_count_b": 400,
    "personality_traits": [
      "Value-King"
    ],
    "professional_traits": [
      "image grounding",
      "multilingual"
    ],
    "best_for": [
      "image understanding",
      "creative writing",
      "general assistant"
    ],
    "active_parameter_count_b": 17,
    "creativity_score": 80,
    "logic_score": 85,
    "efficiency_score": 90,
    "model_family": "Llama",
    "name_within_family": "4 Maverick"
  },
  {
    "id": 203,
    "vendor_id": 15,
    "api_id": "meta-llama/llama-4-scout",
    "slug": "llama-4-scout",
    "display_name": "Llama 4 Scout",
    "display_order": 10,
    "description": "Industry-leading 10M context window on single H100",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 327680,
    "price_prompt_micro": 80000,
    "price_completion_micro": 300000,
    "price_tier": 1,
    "fallback_model_id": 202,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-18T05:43:13.020838+00:00",
    "parameter_count_b": 109,
    "personality_traits": [
      "Efficient",
      "Long-Context-King"
    ],
    "professional_traits": [
      "image understanding"
    ],
    "best_for": [
      "Long document analysis",
      "codebase reasoning",
      "memory-intensive apps"
    ],
    "active_parameter_count_b": 17,
    "creativity_score": 70,
    "logic_score": 75,
    "efficiency_score": 100,
    "model_family": "Llama",
    "name_within_family": "4 Scout"
  },
  {
    "id": 208,
    "vendor_id": 7,
    "api_id": "cohere/command-a",
    "slug": "command-a",
    "display_name": "Cohere: Command A",
    "display_order": 0,
    "description": "Command A is an open-weights 111B parameter model with a 256k context window focused on delivering great performance across agentic, multilingual, and coding use cases.\nCompared to other leading proprietary and open-weights models Command A delivers maximum performance with minimum hardware costs, excelling on business-critical agentic and multilingual tasks.",
    "capabilities": [],
    "context_length": 256000,
    "price_prompt_micro": 2500000,
    "price_completion_micro": 10000000,
    "price_tier": 3,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Command",
    "name_within_family": "A"
  },
  {
    "id": 211,
    "vendor_id": 7,
    "api_id": "cohere/command-r-plus-08-2024",
    "slug": "command-r-plus-08-2024",
    "display_name": "Cohere: Command R+ (08-2024)",
    "display_order": 30,
    "description": "command-r-plus-08-2024 is an update of the [Command R+](/models/cohere/command-r-plus) with roughly 50% higher throughput and 25% lower latencies as compared to the previous Command R+ version, while keeping the hardware footprint the same.\n\nRead the launch post [here](https://docs.cohere.com/changelog/command-gets-refreshed).\n\nUse of this model is subject to Cohere's [Usage Policy](https://docs.cohere.com/docs/usage-policy) and [SaaS Agreement](https://cohere.com/saas-agreement).",
    "capabilities": [
      "tools",
      "tool_choice"
    ],
    "context_length": 128000,
    "price_prompt_micro": 2500000,
    "price_completion_micro": 10000000,
    "price_tier": 3,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T15:04:21.132144+00:00",
    "parameter_count_b": null,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Command",
    "name_within_family": "R+ (08-2024)"
  },
  {
    "id": 209,
    "vendor_id": 7,
    "api_id": "cohere/command-r7b-12-2024",
    "slug": "command-r7b-12-2024",
    "display_name": "Cohere: Command R7B (12-2024)",
    "display_order": 10,
    "description": "Command R7B (12-2024) is a small, fast update of the Command R+ model, delivered in December 2024.",
    "capabilities": [],
    "context_length": 128000,
    "price_prompt_micro": 37500,
    "price_completion_micro": 150000,
    "price_tier": 1,
    "fallback_model_id": null,
    "is_active": true,
    "last_synced_at": "2026-01-07T07:07:05.199715+00:00",
    "created_at": "2026-01-07T07:07:05.199715+00:00",
    "updated_at": "2026-01-13T16:53:58.535853+00:00",
    "parameter_count_b": 7,
    "personality_traits": null,
    "professional_traits": null,
    "best_for": null,
    "active_parameter_count_b": null,
    "creativity_score": null,
    "logic_score": null,
    "efficiency_score": null,
    "model_family": "Command R",
    "name_within_family": "7B 12-2024"
  }
]