{
  "generatedAt": "2026-01-12T08:27:16.366Z",
  "totalModels": 64,
  "models": [
    {
      "id": "188",
      "vendor": "Alibaba",
      "modelFamily": "Tongyi",
      "modelName": "Tongyi DeepResearch 30B A3B",
      "parametersB": "30.5 (3.3 active)",
      "contextK": "128",
      "personalityTraits": "High Conscientiousness, Mod Openness",
      "analyticalTraits": "Agentic reasoning, Web tool integration, ReAct/IterResearch modes",
      "bestFor": "Long-horizon research, Deep information synthesis, Multi-step web research",
      "optimalTeamExamples": "Research Synthesis Lab, Competitive Intelligence, The Interrogator",
      "creativeScore": 6,
      "deductiveScore": 9,
      "specialPropertiesNotes": "MoE ~30.5B/~3.3B active, Qwen3-MoE lineage, Dual inference modes, HLE 32.9, Apache 2.0",
      "api_id": "alibaba/tongyi-deepresearch-30b-a3b",
      "slug": "tongyi-deepresearch-30b-a3b",
      "description": "Tongyi DeepResearch is an agentic large language model developed by Tongyi Lab, with 30 billion total parameters activating only 3 billion per token.",
      "pricing": {
        "prompt": 90000,
        "completion": 400000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "33",
      "vendor": "AllenAI",
      "modelFamily": "OLMo",
      "modelName": "OLMo 3 7B Instruct",
      "parametersB": "7",
      "contextK": "128",
      "personalityTraits": "Balanced, Mod Agreeableness",
      "analyticalTraits": "Instruction-following, Dolci tuning",
      "bestFor": "Everyday tasks, General assistance, Chat",
      "optimalTeamExamples": "General support roles, Customer Success",
      "creativeScore": 6,
      "deductiveScore": 6.5,
      "specialPropertiesNotes": "Apache 2.0, Fully open, Efficient 7B for everyday use",
      "api_id": "allenai/olmo-3-7b-instruct",
      "slug": "olmo-3-7b-instruct",
      "description": "Olmo 3 7B Instruct is a supervised instruction-fine-tuned variant of the Olmo 3 7B base model, optimized for instruction-following, question-answering, and natural conversational dialogue.",
      "pricing": {
        "prompt": 100000,
        "completion": 200000,
        "tier": 1
      },
      "context_length": 65536,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "135",
      "vendor": "Anthropic",
      "modelFamily": "Claude",
      "modelName": "Claude Opus 4.5",
      "parametersB": "Unknown",
      "contextK": "200",
      "personalityTraits": "High Conscientiousness, High Agreeableness, Mod Openness",
      "analyticalTraits": "Extended thinking 64K tokens, Systematic reasoning, 80.9% SWE-bench",
      "bestFor": "Quality control, Nuanced characters, Complex software engineering",
      "optimalTeamExamples": "The Advisory Board, The Publisher, The Psychologists, Heist Crew",
      "creativeScore": 8.5,
      "deductiveScore": 9.5,
      "specialPropertiesNotes": "Best SWE-bench 80.9%, Terminal-Bench 59.3%, 76% fewer tokens at medium effort, Premium pricing",
      "api_id": "anthropic/claude-opus-4.5",
      "slug": "claude-opus-4.5",
      "description": "Claude Opus 4.5 is Anthropic’s frontier reasoning model optimized for complex software engineering, agentic workflows, and long-horizon computer use.",
      "pricing": {
        "prompt": 5000000,
        "completion": 25000000,
        "tier": 3
      },
      "context_length": 200000,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "136",
      "vendor": "Anthropic",
      "modelFamily": "Claude",
      "modelName": "Claude Sonnet 4.5",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "High Conscientiousness, High Agreeableness",
      "analyticalTraits": "Real-world agentic reasoning, 1M context",
      "bestFor": "Project coordination, Balanced creative-analytical, Production workflows",
      "optimalTeamExamples": "Creative Collective, Product Management, The Incubator",
      "creativeScore": 8,
      "deductiveScore": 9,
      "specialPropertiesNotes": "1M context, Agentic workflows, 74.3% SWE-bench, Production workhorse",
      "api_id": "anthropic/claude-sonnet-4.5",
      "slug": "claude-sonnet-4.5",
      "description": "Claude Sonnet 4.5 is Anthropic’s most advanced Sonnet model to date, optimized for real-world agents and coding workflows.",
      "pricing": {
        "prompt": 3000000,
        "completion": 15000000,
        "tier": 3
      },
      "context_length": 1000000,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "137",
      "vendor": "Anthropic",
      "modelFamily": "Claude",
      "modelName": "Claude Opus 4.1",
      "parametersB": "Unknown",
      "contextK": "200",
      "personalityTraits": "High Conscientiousness, High Agreeableness",
      "analyticalTraits": "Extended thinking up to 64K tokens, 74.5% SWE-bench",
      "bestFor": "Complex coding, Systematic analysis",
      "optimalTeamExamples": "Technical teams requiring extended thinking",
      "creativeScore": 8,
      "deductiveScore": 9,
      "specialPropertiesNotes": "Updated flagship, 64K extended thinking, Previous generation Opus",
      "api_id": "anthropic/claude-opus-4.1",
      "slug": "claude-opus-4.1",
      "description": "Claude Opus 4.1 is an updated version of Anthropic’s flagship model, offering improved performance in coding, reasoning, and agentic tasks.",
      "pricing": {
        "prompt": 15000000,
        "completion": 75000000,
        "tier": 3
      },
      "context_length": 200000,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "121",
      "vendor": "Arcee AI",
      "modelFamily": "Trinity",
      "modelName": "Trinity Mini",
      "parametersB": "26 (3 active)",
      "contextK": "128",
      "personalityTraits": "Balanced, Mod Conscientiousness",
      "analyticalTraits": "MoE 128 experts/8 active, Efficient reasoning, Function calling",
      "bestFor": "Multi-step agents, Tool orchestration, Long-context RAG, Agentic workflows",
      "optimalTeamExamples": "Shadow Product Team, Business Development, Product Management",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "MoE 26B/3B active, 10T training tokens, Apache 2.0, Strong tool use, $0.15-0.50 range",
      "api_id": "arcee-ai/trinity-mini",
      "slug": "trinity-mini",
      "description": "Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts language model featuring 128 experts with 8 active per token.",
      "pricing": {
        "prompt": 45000,
        "completion": 150000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "120",
      "vendor": "Arcee AI",
      "modelFamily": "Trinity",
      "modelName": "Trinity Mini (free)",
      "parametersB": "26 (3 active)",
      "contextK": "128",
      "personalityTraits": "Balanced, Mod Conscientiousness",
      "analyticalTraits": "Same as Trinity Mini",
      "bestFor": "Same as Trinity Mini, Free tier",
      "optimalTeamExamples": "Cost-conscious agentic teams",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Free tier of Trinity Mini, Same capabilities",
      "api_id": "arcee-ai/trinity-mini:free",
      "slug": "trinity-mini:free",
      "description": "Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts language model featuring 128 experts with 8 active per token.",
      "pricing": {
        "prompt": 0,
        "completion": 0,
        "tier": 0
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "1",
      "vendor": "ByteDance",
      "modelFamily": "Seed",
      "modelName": "Seed 1.6 Flash",
      "parametersB": "230 (23 active)",
      "contextK": "256",
      "personalityTraits": "High Extraversion, Mod Openness",
      "analyticalTraits": "Adaptive deep thinking, 146.8 tok/s, Ultra-fast multimodal",
      "bestFor": "Real-time multimodal, Visual thinking, Rapid response, 16K output",
      "optimalTeamExamples": "Reality TV Producers, Travel Agency of Vibes, Fast creative teams",
      "creativeScore": 7.5,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "MoE 230B/23B active, Ultra-fast, Reasoning visualization, Multimodal: text/image/video",
      "api_id": "bytedance-seed/seed-1.6-flash",
      "slug": "seed-1.6-flash",
      "description": "Seed 1.6 Flash is an ultra-fast multimodal deep thinking model by ByteDance Seed, supporting both text and visual understanding.",
      "pricing": {
        "prompt": 75000,
        "completion": 300000,
        "tier": 1
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "2",
      "vendor": "ByteDance",
      "modelFamily": "Seed",
      "modelName": "Seed 1.6",
      "parametersB": "230 (23 active)",
      "contextK": "256",
      "personalityTraits": "Mod Openness, Mod Extraversion",
      "analyticalTraits": "Adaptive deep thinking, Multimodal fusion",
      "bestFor": "General-purpose multimodal, Comprehensive reasoning",
      "optimalTeamExamples": "Multimodal analysis teams",
      "creativeScore": 7,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "MoE 230B/23B active, Slower than Flash but deeper thinking",
      "api_id": "bytedance-seed/seed-1.6",
      "slug": "seed-1.6",
      "description": "Seed 1.6 is a general-purpose model released by the ByteDance Seed team.",
      "pricing": {
        "prompt": 250000,
        "completion": 2000000,
        "tier": 2
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "209",
      "vendor": "Cohere",
      "modelFamily": "Command R",
      "modelName": "Command R7B 12-2024",
      "parametersB": "7-8",
      "contextK": "128",
      "personalityTraits": "Mod Agreeableness, Mod Conscientiousness",
      "analyticalTraits": "RAG optimization, Structured outputs, Tool use, 23 languages",
      "bestFor": "RAG, Tool use, Code assistants, Low-latency chatbots, Edge deployment",
      "optimalTeamExamples": "Customer Success, The Concierge, RAG teams",
      "creativeScore": 6.5,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Latest 7B, Strong RAG, 4K output, $0.0375/$0.15 per 1M, Edge-compatible, IFEval 77.9",
      "api_id": "cohere/command-r7b-12-2024",
      "slug": "command-r7b-12-2024",
      "description": "Command R7B (12-2024) is a small, fast update of the Command R+ model, delivered in December 2024.",
      "pricing": {
        "prompt": 37500,
        "completion": 150000,
        "tier": 1
      },
      "context_length": 128000,
      "capabilities": []
    },
    {
      "id": "210",
      "vendor": "Cohere",
      "modelFamily": "Command R",
      "modelName": "Command R 08-2024",
      "parametersB": "~35",
      "contextK": "128",
      "personalityTraits": "Mod Agreeableness, High Conscientiousness",
      "analyticalTraits": "Enterprise RAG, Grounded generation, Citations",
      "bestFor": "Enterprise RAG, Document analysis, Retrieval workflows",
      "optimalTeamExamples": "Enterprise RAG teams, Document processing",
      "creativeScore": 7,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Enterprise-focused, Strong citations, 10+ languages",
      "api_id": "cohere/command-r-08-2024",
      "slug": "command-r-08-2024",
      "description": "command-r-08-2024 is an update of the [Command R](/models/cohere/command-r) with improved performance for multilingual retrieval-augmented generation (RAG) and tool use.",
      "pricing": {
        "prompt": 150000,
        "completion": 600000,
        "tier": 1
      },
      "context_length": 128000,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "210",
      "vendor": "Cohere",
      "modelFamily": "Command R",
      "modelName": "Command R+ 08-2024",
      "parametersB": "104",
      "contextK": "128",
      "personalityTraits": "High Agreeableness, High Conscientiousness",
      "analyticalTraits": "Multi-step tool use, Self-correction, Inline citations, 50% throughput boost",
      "bestFor": "Enterprise RAG with citations, CRM automation, Multi-step agents",
      "optimalTeamExamples": "Rfp Response Unit, Legal Compliance, Organization Core",
      "creativeScore": 7,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "104B dense, 50% faster than previous, Multi-step tools, CC-BY-NC license",
      "api_id": "cohere/command-r-08-2024",
      "slug": "command-r-08-2024",
      "description": "command-r-08-2024 is an update of the [Command R](/models/cohere/command-r) with improved performance for multilingual retrieval-augmented generation (RAG) and tool use.",
      "pricing": {
        "prompt": 150000,
        "completion": 600000,
        "tier": 1
      },
      "context_length": 128000,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "128",
      "vendor": "DeepSeek",
      "modelFamily": "R1",
      "modelName": "DeepSeek R1",
      "parametersB": "671 (37 active)",
      "contextK": "128",
      "personalityTraits": "High Openness (reasoning-focused), Mod Conscientiousness",
      "analyticalTraits": "Chain-of-thought, Self-verification, 91.4% AIME, RL training",
      "bestFor": "Mathematical reasoning, Logic specialist, Systematic analysis, Exceptional value",
      "optimalTeamExamples": "The Think Tank, Occult Investigation Unit, Crisis Management",
      "creativeScore": 6,
      "deductiveScore": 10,
      "specialPropertiesNotes": "MoE 671B/37B active, Open-source, 90% cost savings, $0.55/$2.19, Exceptional reasoning",
      "api_id": "deepseek/deepseek-r1-0528",
      "slug": "deepseek-r1-0528",
      "description": "May 28th update to the [original DeepSeek R1](/deepseek/deepseek-r1) Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens.",
      "pricing": {
        "prompt": 400000,
        "completion": 1750000,
        "tier": 2
      },
      "context_length": 163840,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "132",
      "vendor": "DeepSeek",
      "modelFamily": "R1 Distilled",
      "modelName": "DeepSeek R1 Distill Llama 70B",
      "parametersB": "70",
      "contextK": "128",
      "personalityTraits": "Mod Openness, Mod Conscientiousness",
      "analyticalTraits": "80% of R1 reasoning, Llama base",
      "bestFor": "Cost-effective reasoning on Llama architecture",
      "optimalTeamExamples": "Budget reasoning teams preferring Llama",
      "creativeScore": 5.5,
      "deductiveScore": 9,
      "specialPropertiesNotes": "70B Llama distill, 80% of R1 performance, 95% cost savings",
      "api_id": "deepseek/deepseek-r1-distill-llama-70b",
      "slug": "deepseek-r1-distill-llama-70b",
      "description": "DeepSeek R1 Distill Llama 70B is a distilled large language model based on [Llama-3.3-70B-Instruct](/meta-llama/llama-3.3-70b-instruct), using outputs from [DeepSeek R1](/deepseek/deepseek-r1).",
      "pricing": {
        "prompt": 30000,
        "completion": 110000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "130",
      "vendor": "DeepSeek",
      "modelFamily": "R1 Distilled",
      "modelName": "DeepSeek R1 Distill Qwen 32B",
      "parametersB": "32",
      "contextK": "128",
      "personalityTraits": "Mod Openness",
      "analyticalTraits": "Efficient reasoning, Qwen base",
      "bestFor": "Balanced reasoning at 32B, Efficient deployment",
      "optimalTeamExamples": "Cost-sensitive analytical teams",
      "creativeScore": 5,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "32B Qwen distill, Excellent value, 80% of R1",
      "api_id": "deepseek/deepseek-r1-distill-qwen-32b",
      "slug": "deepseek-r1-distill-qwen-32b",
      "description": "DeepSeek R1 Distill Qwen 32B is a distilled large language model based on [Qwen 2.5 32B](https://huggingface.co/Qwen/Qwen2.5-32B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1).",
      "pricing": {
        "prompt": 270000,
        "completion": 270000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "reasoning"
      ]
    },
    {
      "id": "131",
      "vendor": "DeepSeek",
      "modelFamily": "R1 Distilled",
      "modelName": "DeepSeek R1 Distill Qwen 14B",
      "parametersB": "14",
      "contextK": "128",
      "personalityTraits": "Mod Openness",
      "analyticalTraits": "Compact reasoning",
      "bestFor": "Edge reasoning, Resource-constrained",
      "optimalTeamExamples": "Budget analytical roles, Edge deployment",
      "creativeScore": 4.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "14B Qwen distill, Smallest viable reasoning",
      "api_id": "deepseek/deepseek-r1-distill-qwen-14b",
      "slug": "deepseek-r1-distill-qwen-14b",
      "description": "DeepSeek R1 Distill Qwen 14B is a distilled large language model based on [Qwen 2.5 14B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B), using outputs from [DeepSeek R1](/deepseek/deepseek-r1).",
      "pricing": {
        "prompt": 150000,
        "completion": 150000,
        "tier": 1
      },
      "context_length": 32768,
      "capabilities": [
        "reasoning"
      ]
    },
    {
      "id": "133",
      "vendor": "DeepSeek",
      "modelFamily": "V3",
      "modelName": "DeepSeek V3",
      "parametersB": "671 (37 active)",
      "contextK": "128",
      "personalityTraits": "Balanced, High Conscientiousness",
      "analyticalTraits": "General-purpose, Latest generation",
      "bestFor": "Versatile general-purpose tasks, Cost-effective",
      "optimalTeamExamples": "General operations teams",
      "creativeScore": 6.5,
      "deductiveScore": 9,
      "specialPropertiesNotes": "MoE 671B/37B active, $0.28/$0.42, 90% below GPT-4.1, Latest general model",
      "api_id": "deepseek/deepseek-chat",
      "slug": "deepseek-chat",
      "description": "DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions.",
      "pricing": {
        "prompt": 300000,
        "completion": 1200000,
        "tier": 2
      },
      "context_length": 163840,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "12",
      "vendor": "Google",
      "modelFamily": "Gemini",
      "modelName": "Gemini 3 Flash Preview",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "Mod all dimensions",
      "analyticalTraits": "High-speed thinking, Agentic workflows, 1M context",
      "bestFor": "Fast agentic workflows, High-throughput thinking",
      "optimalTeamExamples": "Fast agentic teams, The Daily Dispatch",
      "creativeScore": 7,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "1M context, Preview experimental, High-speed",
      "api_id": "google/gemini-3-flash-preview",
      "slug": "gemini-3-flash-preview",
      "description": "Gemini 3 Flash Preview is a high speed, high value thinking model designed for agentic workflows, multi turn chat, and coding assistance.",
      "pricing": {
        "prompt": 500000,
        "completion": 3000000,
        "tier": 2
      },
      "context_length": 1048576,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "14",
      "vendor": "Google",
      "modelFamily": "Gemini",
      "modelName": "Gemini 3 Pro Preview",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "Lower Agreeableness/Conscientiousness, High Openness",
      "analyticalTraits": "PhD-level reasoning, Dynamic Thinking, Multimodal",
      "bestFor": "Complex multimodal reasoning, Strategic planning, Visual+text",
      "optimalTeamExamples": "The Hedge Fund, Competitive Intelligence, Michelin Inspectors",
      "creativeScore": 7.5,
      "deductiveScore": 9.5,
      "specialPropertiesNotes": "Flagship frontier, 1M context, MMMU-Pro 81%, SWE-bench 76.2%, 10 FPS video, Pixel-precise pointing",
      "api_id": "google/gemini-3-pro-preview",
      "slug": "gemini-3-pro-preview",
      "description": "Gemini 3 Pro is Google’s flagship frontier model for high-precision multimodal reasoning, combining strong performance across text, image, video, audio, and code with a 1M-token context window.",
      "pricing": {
        "prompt": 2000000,
        "completion": 12000000,
        "tier": 3
      },
      "context_length": 1048576,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "16",
      "vendor": "Google",
      "modelFamily": "Gemini",
      "modelName": "Gemini 2.5 Flash Preview 09-2025",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "Mod all dimensions",
      "analyticalTraits": "State-of-the-art reasoning, coding, math, 392 tok/s",
      "bestFor": "Advanced reasoning at high speed",
      "optimalTeamExamples": "High-volume advanced processing",
      "creativeScore": 6.5,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "Preview status, State-of-the-art Flash",
      "api_id": "google/gemini-2.5-flash-preview-09-2025",
      "slug": "gemini-2.5-flash-preview-09-2025",
      "description": "Gemini 2.5 Flash Preview September 2025 Checkpoint is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks.",
      "pricing": {
        "prompt": 300000,
        "completion": 2500000,
        "tier": 2
      },
      "context_length": 1048576,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "17",
      "vendor": "Google",
      "modelFamily": "Gemini",
      "modelName": "Gemini 2.5 Flash Lite Preview 09-2025",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "Mod all dimensions",
      "analyticalTraits": "Ultra-low latency, Lightweight reasoning, 392.8 tok/s, 0.29s TTFT",
      "bestFor": "Ultra-fast lightweight reasoning",
      "optimalTeamExamples": "Real-time lightweight applications",
      "creativeScore": 6,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Ultra-low latency, 392.8 tok/s, 0.29s TTFT, Lightest reasoning",
      "api_id": "google/gemini-2.5-flash-lite-preview-09-2025",
      "slug": "gemini-2.5-flash-lite-preview-09-2025",
      "description": "Gemini 2.5 Flash-Lite is a lightweight reasoning model in the Gemini 2.5 family, optimized for ultra-low latency and cost efficiency.",
      "pricing": {
        "prompt": 100000,
        "completion": 400000,
        "tier": 1
      },
      "context_length": 1048576,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "19",
      "vendor": "Google",
      "modelFamily": "Gemini",
      "modelName": "Gemini 2.5 Flash Lite",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "Mod all dimensions",
      "analyticalTraits": "Production lightweight, Low latency",
      "bestFor": "Production lightweight reasoning",
      "optimalTeamExamples": "Production lightweight apps",
      "creativeScore": 6,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Production Lite version",
      "api_id": "google/gemini-2.5-flash-lite",
      "slug": "gemini-2.5-flash-lite",
      "description": "Gemini 2.5 Flash-Lite is a lightweight reasoning model in the Gemini 2.5 family, optimized for ultra-low latency and cost efficiency.",
      "pricing": {
        "prompt": 100000,
        "completion": 400000,
        "tier": 1
      },
      "context_length": 1048576,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "20",
      "vendor": "Google",
      "modelFamily": "Gemini",
      "modelName": "Gemini 2.5 Flash",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "Mod all dimensions",
      "analyticalTraits": "Thinking mode optional, 392 tok/s, Production workhorse",
      "bestFor": "High-volume processing, Fast multimodal, Production scale",
      "optimalTeamExamples": "The Daily Dispatch, The Newsroom, Customer Success",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "$0.15/$3.50 thinking, $0.60 standard, 1M context, Production workhorse",
      "api_id": "google/gemini-2.5-flash",
      "slug": "gemini-2.5-flash",
      "description": "Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks.",
      "pricing": {
        "prompt": 300000,
        "completion": 2500000,
        "tier": 2
      },
      "context_length": 1048576,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "29",
      "vendor": "Google",
      "modelFamily": "Gemini",
      "modelName": "Gemini 2.0 Flash Exp",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "Mod all dimensions",
      "analyticalTraits": "Experimental Flash",
      "bestFor": "Experimental Flash testing",
      "optimalTeamExamples": "Experimental teams",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Experimental release",
      "api_id": "google/gemini-2.0-flash-001",
      "slug": "gemini-2.0-flash-001",
      "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5).",
      "pricing": {
        "prompt": 100000,
        "completion": 400000,
        "tier": 1
      },
      "context_length": 1048576,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "29",
      "vendor": "Google",
      "modelFamily": "Gemini",
      "modelName": "Gemini 2.0 Flash",
      "parametersB": "Unknown",
      "contextK": "1000",
      "personalityTraits": "Mod all dimensions",
      "analyticalTraits": "Latest production Flash",
      "bestFor": "Production Flash applications",
      "optimalTeamExamples": "Production Flash teams",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Latest production Flash model",
      "api_id": "google/gemini-2.0-flash-001",
      "slug": "gemini-2.0-flash-001",
      "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5).",
      "pricing": {
        "prompt": 100000,
        "completion": 400000,
        "tier": 1
      },
      "context_length": 1048576,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "219",
      "vendor": "Gryphe",
      "modelFamily": "MythoMax",
      "modelName": "MythoMax 13B",
      "parametersB": "13",
      "contextK": "32",
      "personalityTraits": "Very High Openness, High Extraversion, Creative-dominant",
      "analyticalTraits": "Low systematic analysis",
      "bestFor": "Fantasy worldbuilding, Character-driven stories, Adventure narratives, Creative writing",
      "optimalTeamExamples": "TTRPG Campaign, Alien Archaeologists, Time Travel Tourism, Dungeon Masters Forge",
      "creativeScore": 9,
      "deductiveScore": 4.5,
      "specialPropertiesNotes": "Best creative coherence for 13B, Power-fantasy tendency, Uncensored, MythoLogic-L2 + Huginn merge",
      "api_id": "gryphe/mythomax-l2-13b",
      "slug": "mythomax-l2-13b",
      "description": "One of the highest performing and most popular fine-tunes of Llama 2 13B, with rich descriptions and roleplay.",
      "pricing": {
        "prompt": 60000,
        "completion": 60000,
        "tier": 1
      },
      "context_length": 4096,
      "capabilities": []
    },
    {
      "id": "204",
      "vendor": "Meta",
      "modelFamily": "Llama",
      "modelName": "Llama 3.3 70B Instruct",
      "parametersB": "70",
      "contextK": "128",
      "personalityTraits": "Balanced all dimensions",
      "analyticalTraits": "General reasoning, Matches 405B performance",
      "bestFor": "Dialogue, Conversational depth, Character-driven stories, Cost-effective general purpose",
      "optimalTeamExamples": "Dating Council, Relationship Counselors, Rap Battle League, Brainstorming Collective",
      "creativeScore": 8,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Best dialogue naturalness, Open weights, MATH 77.0, HumanEval 88.4, 276 tok/s on Groq, ~$0.20",
      "api_id": "meta-llama/llama-3.3-70b-instruct",
      "slug": "llama-3.3-70b-instruct",
      "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out).",
      "pricing": {
        "prompt": 100000,
        "completion": 320000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "206",
      "vendor": "Meta",
      "modelFamily": "Llama",
      "modelName": "Llama 3.1 405B Instruct",
      "parametersB": "405",
      "contextK": "128",
      "personalityTraits": "Balanced, Mod all dimensions",
      "analyticalTraits": "Massive scale reasoning",
      "bestFor": "Frontier-scale general intelligence",
      "optimalTeamExamples": "Large-scale comprehensive teams",
      "creativeScore": 7.5,
      "deductiveScore": 9,
      "specialPropertiesNotes": "Massive 405B flagship, Open weights, Frontier capability",
      "api_id": "meta-llama/llama-3.1-405b-instruct",
      "slug": "llama-3.1-405b-instruct",
      "description": "The highly anticipated 400B class of Llama3 is here! Clocking in at 128k context with impressive eval scores, the Meta AI team continues to push the frontier of open-source LLMs.\n\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors.",
      "pricing": {
        "prompt": 3500000,
        "completion": 3500000,
        "tier": 2
      },
      "context_length": 10000,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "205",
      "vendor": "Meta",
      "modelFamily": "Llama",
      "modelName": "Llama 3.1 8B Instruct",
      "parametersB": "8",
      "contextK": "128",
      "personalityTraits": "Balanced",
      "analyticalTraits": "Efficient general-purpose",
      "bestFor": "Efficient general tasks",
      "optimalTeamExamples": "Budget general teams",
      "creativeScore": 6.5,
      "deductiveScore": 6.5,
      "specialPropertiesNotes": "Efficient 8B variant, Open weights",
      "api_id": "meta-llama/llama-3.1-8b-instruct",
      "slug": "llama-3.1-8b-instruct",
      "description": "Meta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors.",
      "pricing": {
        "prompt": 20000,
        "completion": 30000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "212",
      "vendor": "Microsoft",
      "modelFamily": "Phi",
      "modelName": "Phi 4",
      "parametersB": "14",
      "contextK": "16",
      "personalityTraits": "Mod Conscientiousness, Mod Openness",
      "analyticalTraits": "Efficient small model, 1955 tok/s on Xeon 6",
      "bestFor": "Edge reasoning, Efficient deployment, Resource-constrained",
      "optimalTeamExamples": "Edge deployment, Efficient teams",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "14B efficient, 16K context (extended from 4K), 1955 tok/s, Edge-optimized, Open-source",
      "api_id": "microsoft/phi-4",
      "slug": "phi-4",
      "description": "[Microsoft Research](/microsoft) Phi-4 is designed to perform well in complex reasoning tasks and can operate efficiently in situations with limited memory or where quick responses are needed.",
      "pricing": {
        "prompt": 60000,
        "completion": 140000,
        "tier": 1
      },
      "context_length": 16384,
      "capabilities": []
    },
    {
      "id": "3",
      "vendor": "MiniMax",
      "modelFamily": "MiniMax",
      "modelName": "MiniMax M2.1",
      "parametersB": "10",
      "contextK": 192,
      "personalityTraits": "Mod Conscientiousness",
      "analyticalTraits": "Coding and agents focus",
      "bestFor": "Lightweight coding, Agent workflows",
      "optimalTeamExamples": "Budget coding teams",
      "creativeScore": 6,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "10B lightweight, Coding + agents",
      "api_id": "minimax/minimax-m2.1",
      "slug": "minimax-m2.1",
      "description": "MiniMax-M2.1 is a lightweight, state-of-the-art large language model optimized for coding, agentic workflows, and modern application development.",
      "pricing": {
        "prompt": 120000,
        "completion": 480000,
        "tier": 1
      },
      "context_length": 196608,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "4",
      "vendor": "MiniMax",
      "modelFamily": "MiniMax",
      "modelName": "MiniMax M2",
      "parametersB": "Unknown",
      "contextK": 192,
      "personalityTraits": "Mod Conscientiousness",
      "analyticalTraits": "Previous generation compact",
      "bestFor": "Previous gen compact tasks",
      "optimalTeamExamples": "Legacy compact teams",
      "creativeScore": 5.5,
      "deductiveScore": 7,
      "specialPropertiesNotes": "Previous generation",
      "api_id": "minimax/minimax-m2",
      "slug": "minimax-m2",
      "description": "MiniMax-M2 is a compact, high-efficiency large language model optimized for end-to-end coding and agentic workflows.",
      "pricing": {
        "prompt": 200000,
        "completion": 1000000,
        "tier": 2
      },
      "context_length": 196608,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "96",
      "vendor": "Mistral",
      "modelFamily": "Large",
      "modelName": "Mistral Large 3 2512",
      "parametersB": "675 (41 active)",
      "contextK": "262",
      "personalityTraits": "Mod Conscientiousness, Balanced",
      "analyticalTraits": "Granular MoE, 39B language + 2.5B vision, Speculative decoding",
      "bestFor": "Enterprise RAG, Multilingual, On-prem, Multimodal",
      "optimalTeamExamples": "International operations teams, Translator Corps",
      "creativeScore": 7,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "MoE 675B/41B active, Apache 2.0, Vision 2.5B, FP8/NVFP4 quantization, Multilingual",
      "api_id": "mistralai/mistral-large-2512",
      "slug": "mistral-large-2512",
      "description": "Mistral Large 3 2512 is Mistral’s most capable model to date, featuring a sparse mixture-of-experts architecture with 41B active parameters (675B total), and released under the Apache 2.0 license.",
      "pricing": {
        "prompt": 500000,
        "completion": 1500000,
        "tier": 2
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "93",
      "vendor": "Mistral",
      "modelFamily": "Ministral",
      "modelName": "Ministral 3 14B 2512",
      "parametersB": "14 (13.5+0.4 vision)",
      "contextK": "262",
      "personalityTraits": "Mod Conscientiousness, Balanced",
      "analyticalTraits": "Structured reasoning, High-res image understanding, Vision 0.4B",
      "bestFor": "Visual creative, Multimodal coordination, High-res image analysis",
      "optimalTeamExamples": "Home Space Design, Michelin Inspectors, The Studio",
      "creativeScore": 7,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Vision-capable, Approaches 24B performance, Apache 2.0, Largest Ministral",
      "api_id": "mistralai/ministral-14b-2512",
      "slug": "ministral-14b-2512",
      "description": "The largest model in the Ministral 3 family, Ministral 3 14B offers frontier capabilities and performance comparable to its larger Mistral Small 3.2 24B counterpart.",
      "pricing": {
        "prompt": 200000,
        "completion": 200000,
        "tier": 1
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "94",
      "vendor": "Mistral",
      "modelFamily": "Ministral",
      "modelName": "Ministral 3 8B 2512",
      "parametersB": "8.8 (8.4+0.4 vision)",
      "contextK": "262",
      "personalityTraits": "Balanced",
      "analyticalTraits": "3 variants: Base/Instruct/Reasoning, 237.5 tok/s, Vision 0.4B",
      "bestFor": "Edge deployment, Efficient generalist, Math+logic creative, Vision tasks",
      "optimalTeamExamples": "Zombie Survival Council, Eli Varied Team",
      "creativeScore": 6.5,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "<12GB quantized, 237.5 tok/s, Vision-capable, $0.15/$0.15, Reasoning variant available",
      "api_id": "mistralai/ministral-8b-2512",
      "slug": "ministral-8b-2512",
      "description": "A balanced model in the Ministral 3 family, Ministral 3 8B is a powerful, efficient tiny language model with vision capabilities.",
      "pricing": {
        "prompt": 150000,
        "completion": 150000,
        "tier": 1
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "95",
      "vendor": "Mistral",
      "modelFamily": "Ministral",
      "modelName": "Ministral 3 3B 2512",
      "parametersB": "3.8 (3.4+0.4 vision)",
      "contextK": "262",
      "personalityTraits": "Balanced",
      "analyticalTraits": "Smallest footprint, Fastest inference, Vision 0.4B",
      "bestFor": "Mobile, IoT, Local privacy, Ultra-edge vision",
      "optimalTeamExamples": "Mobile/IoT teams",
      "creativeScore": 6,
      "deductiveScore": 6.5,
      "specialPropertiesNotes": "Smallest Ministral, Vision on ultra-constrained hardware",
      "api_id": "mistralai/ministral-3b-2512",
      "slug": "ministral-3b-2512",
      "description": "The smallest model in the Ministral 3 family, Ministral 3 3B is a powerful, efficient tiny language model with vision capabilities.",
      "pricing": {
        "prompt": 100000,
        "completion": 100000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "92",
      "vendor": "Mistral",
      "modelFamily": "Devstral",
      "modelName": "Devstral 2 2512",
      "parametersB": "123",
      "contextK": "262",
      "personalityTraits": "High Conscientiousness, Mod Openness",
      "analyticalTraits": "Coding specialist",
      "bestFor": "Advanced coding tasks",
      "optimalTeamExamples": "Coding specialist teams",
      "creativeScore": 6.5,
      "deductiveScore": 9,
      "specialPropertiesNotes": "123B coding specialist",
      "api_id": "mistralai/devstral-2512",
      "slug": "devstral-2512",
      "description": "Devstral 2 is a state-of-the-art open-source model by Mistral AI specializing in agentic coding.",
      "pricing": {
        "prompt": 50000,
        "completion": 220000,
        "tier": 1
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "91",
      "vendor": "Mistral",
      "modelFamily": "Devstral",
      "modelName": "Devstral 2 2512 (free)",
      "parametersB": "123",
      "contextK": "262",
      "personalityTraits": "High Conscientiousness, Mod Openness",
      "analyticalTraits": "Coding specialist",
      "bestFor": "Same as Devstral 2, Free tier",
      "optimalTeamExamples": "Budget coding teams",
      "creativeScore": 6.5,
      "deductiveScore": 9,
      "specialPropertiesNotes": "Free tier coding specialist",
      "api_id": "mistralai/devstral-2512:free",
      "slug": "devstral-2512:free",
      "description": "Devstral 2 is a state-of-the-art open-source model by Mistral AI specializing in agentic coding.",
      "pricing": {
        "prompt": 0,
        "completion": 0,
        "tier": 0
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "108",
      "vendor": "Mistral",
      "modelFamily": "Large",
      "modelName": "Mistral Large 2",
      "parametersB": "Unknown",
      "contextK": "262",
      "personalityTraits": "Mod Conscientiousness",
      "analyticalTraits": "Previous flagship",
      "bestFor": "Legacy large-scale tasks",
      "optimalTeamExamples": "Legacy teams",
      "creativeScore": 7,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Previous flagship",
      "api_id": "mistralai/mistral-large-2411",
      "slug": "mistral-large-2411",
      "description": "Mistral Large 2 2411 is an update of [Mistral Large 2](/mistralai/mistral-large) released together with [Pixtral Large 2411](/mistralai/pixtral-large-2411)\n\nIt provides a significant upgrade on the previous [Mistral Large 24.07](/mistralai/mistral-large-2407), with notable improvements in long context understanding, a new system prompt, and more accurate function calling.",
      "pricing": {
        "prompt": 2000000,
        "completion": 6000000,
        "tier": 2
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "114",
      "vendor": "Mistral",
      "modelFamily": "Nemo",
      "modelName": "Mistral Nemo",
      "parametersB": "12",
      "contextK": "262",
      "personalityTraits": "Balanced",
      "analyticalTraits": "Efficient 12B",
      "bestFor": "General 12B tasks",
      "optimalTeamExamples": "Mid-size general teams",
      "creativeScore": 6.5,
      "deductiveScore": 7,
      "specialPropertiesNotes": "Efficient 12B model",
      "api_id": "mistralai/mistral-nemo",
      "slug": "mistral-nemo",
      "description": "A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.\n\nThe model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.\n\nIt supports function calling and is released under the Apache 2.0 license.",
      "pricing": {
        "prompt": 20000,
        "completion": 40000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "115",
      "vendor": "Mistral",
      "modelFamily": "Mixtral",
      "modelName": "Mixtral 8x22B Instruct",
      "parametersB": "141 (39 active)",
      "contextK": "64",
      "personalityTraits": "Balanced",
      "analyticalTraits": "Larger MoE",
      "bestFor": "Larger MoE instruction tasks",
      "optimalTeamExamples": "Larger MoE teams",
      "creativeScore": 7,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Larger MoE variant, 8x22B",
      "api_id": "mistralai/mixtral-8x22b-instruct",
      "slug": "mixtral-8x22b-instruct",
      "description": "Mistral's official instruct fine-tuned version of [Mixtral 8x22B](/models/mistralai/mixtral-8x22b).",
      "pricing": {
        "prompt": 2000000,
        "completion": 6000000,
        "tier": 2
      },
      "context_length": 65536,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "35",
      "vendor": "NVIDIA",
      "modelFamily": "Nemotron",
      "modelName": "Nemotron 3 Nano 30B A3B",
      "parametersB": "30 (3 active)",
      "contextK": 256,
      "personalityTraits": "Mod Conscientiousness",
      "analyticalTraits": "MoE optimized for NVIDIA hardware",
      "bestFor": "NVIDIA hardware optimization",
      "optimalTeamExamples": "NVIDIA-optimized teams",
      "creativeScore": 6,
      "deductiveScore": 8,
      "specialPropertiesNotes": "MoE 30B/3B active, NVIDIA hardware optimized",
      "api_id": "nvidia/nemotron-3-nano-30b-a3b",
      "slug": "nemotron-3-nano-30b-a3b",
      "description": "NVIDIA Nemotron 3 Nano 30B A3B is a small language MoE model with highest compute efficiency and accuracy for developers to build specialized agentic AI systems.\n\nThe model is fully open with open-weights, datasets and recipes so developers can easily\ncustomize, optimize, and deploy the model on their infrastructure for maximum privacy and\nsecurity.\n\nNote: For the free endpoint, all prompts and output are logged to improve the provider's model and its product and services.",
      "pricing": {
        "prompt": 60000,
        "completion": 240000,
        "tier": 1
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "35",
      "vendor": "NVIDIA",
      "modelFamily": "Nemotron",
      "modelName": "Nemotron 3 Nano 30B A3B (free)",
      "parametersB": "30 (3 active)",
      "contextK": 256,
      "personalityTraits": "Mod Conscientiousness",
      "analyticalTraits": "Same as Nemotron",
      "bestFor": "Same as Nemotron, Free tier",
      "optimalTeamExamples": "Budget NVIDIA teams",
      "creativeScore": 6,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Free tier",
      "api_id": "nvidia/nemotron-3-nano-30b-a3b",
      "slug": "nemotron-3-nano-30b-a3b",
      "description": "NVIDIA Nemotron 3 Nano 30B A3B is a small language MoE model with highest compute efficiency and accuracy for developers to build specialized agentic AI systems.\n\nThe model is fully open with open-weights, datasets and recipes so developers can easily\ncustomize, optimize, and deploy the model on their infrastructure for maximum privacy and\nsecurity.\n\nNote: For the free endpoint, all prompts and output are logged to improve the provider's model and its product and services.",
      "pricing": {
        "prompt": 60000,
        "completion": 240000,
        "tier": 1
      },
      "context_length": 262144,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "38",
      "vendor": "OpenAI",
      "modelFamily": "GPT-5",
      "modelName": "GPT-5.2 Chat",
      "parametersB": "Unknown",
      "contextK": 125,
      "personalityTraits": "Mod Agreeableness, Mod Conscientiousness",
      "analyticalTraits": "Fast lightweight for chat (Instant mode)",
      "bestFor": "Rapid chat responses",
      "optimalTeamExamples": "Fast chat teams",
      "creativeScore": 7,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Fast lightweight GPT-5, Instant mode",
      "api_id": "openai/gpt-5.2-chat",
      "slug": "gpt-5.2-chat",
      "description": "GPT-5.2 Chat (AKA Instant) is the fast, lightweight member of the 5.2 family, optimized for low-latency chat while retaining strong general intelligence.",
      "pricing": {
        "prompt": 1750000,
        "completion": 14000000,
        "tier": 3
      },
      "context_length": 128000,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "40",
      "vendor": "OpenAI",
      "modelFamily": "GPT-5",
      "modelName": "GPT-5.2",
      "parametersB": "Unknown",
      "contextK": "400",
      "personalityTraits": "High Conscientiousness, Mod Openness",
      "analyticalTraits": "Adaptive reasoning, 400K context",
      "bestFor": "Frontier adaptive reasoning",
      "optimalTeamExamples": "Advanced reasoning teams",
      "creativeScore": 7.5,
      "deductiveScore": 9.5,
      "specialPropertiesNotes": "Latest frontier, Adaptive reasoning, 400K context",
      "api_id": "openai/gpt-5.2",
      "slug": "gpt-5.2",
      "description": "GPT-5.2 is the latest frontier-grade model in the GPT-5 series, offering stronger agentic and long context perfomance compared to GPT-5.1.",
      "pricing": {
        "prompt": 1750000,
        "completion": 14000000,
        "tier": 3
      },
      "context_length": 400000,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "89",
      "vendor": "OpenAI",
      "modelFamily": "GPT-4",
      "modelName": "GPT-4.5 Turbo",
      "parametersB": "Unknown",
      "contextK": "128",
      "personalityTraits": "High Conscientiousness, High Agreeableness",
      "analyticalTraits": "Enhanced reasoning over GPT-4",
      "bestFor": "Enhanced GPT-4 applications",
      "optimalTeamExamples": "Enhanced GPT-4 teams",
      "creativeScore": 7.5,
      "deductiveScore": 9,
      "specialPropertiesNotes": "Enhanced GPT-4, Better reasoning",
      "api_id": "openai/gpt-4",
      "slug": "gpt-4",
      "description": "OpenAI's flagship model, GPT-4 is a large-scale multimodal language model capable of solving difficult problems with greater accuracy than previous models due to its broader general knowledge and advanced reasoning capabilities.",
      "pricing": {
        "prompt": 30000000,
        "completion": 60000000,
        "tier": 3
      },
      "context_length": 8191,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "82",
      "vendor": "OpenAI",
      "modelFamily": "GPT-4",
      "modelName": "GPT-4 Turbo",
      "parametersB": "Unknown",
      "contextK": "128",
      "personalityTraits": "High Conscientiousness, High Agreeableness",
      "analyticalTraits": "Previous generation flagship",
      "bestFor": "Previous gen flagship tasks",
      "optimalTeamExamples": "Legacy GPT-4 teams",
      "creativeScore": 7.5,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "Previous generation flagship",
      "api_id": "openai/gpt-4-turbo",
      "slug": "gpt-4-turbo",
      "description": "The latest GPT-4 Turbo model with vision capabilities.",
      "pricing": {
        "prompt": 10000000,
        "completion": 30000000,
        "tier": 3
      },
      "context_length": 128000,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "80",
      "vendor": "OpenAI",
      "modelFamily": "GPT-4",
      "modelName": "GPT-4o",
      "parametersB": "Unknown",
      "contextK": "128",
      "personalityTraits": "High Conscientiousness, Mod Agreeableness",
      "analyticalTraits": "Omni multimodal",
      "bestFor": "Multimodal applications",
      "optimalTeamExamples": "Multimodal teams",
      "creativeScore": 7.5,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "Omni multimodal capabilities",
      "api_id": "openai/gpt-4o",
      "slug": "gpt-4o",
      "description": "GPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs.",
      "pricing": {
        "prompt": 2500000,
        "completion": 10000000,
        "tier": 3
      },
      "context_length": 128000,
      "capabilities": [
        "tools",
        "tool_choice",
        "web_search"
      ]
    },
    {
      "id": "78",
      "vendor": "OpenAI",
      "modelFamily": "GPT-4",
      "modelName": "GPT-4o Mini",
      "parametersB": "Unknown",
      "contextK": "128",
      "personalityTraits": "Mod Agreeableness, Mod Conscientiousness",
      "analyticalTraits": "Efficient small omni variant",
      "bestFor": "Efficient multimodal",
      "optimalTeamExamples": "Efficient omni teams",
      "creativeScore": 7,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Efficient small omni variant",
      "api_id": "openai/gpt-4o-mini",
      "slug": "gpt-4o-mini",
      "description": "GPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo).",
      "pricing": {
        "prompt": 150000,
        "completion": 600000,
        "tier": 1
      },
      "context_length": 128000,
      "capabilities": [
        "tools",
        "tool_choice",
        "web_search"
      ]
    },
    {
      "id": "73",
      "vendor": "OpenAI",
      "modelFamily": "o",
      "modelName": "o1",
      "parametersB": "Unknown",
      "contextK": "128",
      "personalityTraits": "High Openness (reasoning-focused), High Conscientiousness",
      "analyticalTraits": "Reasoning-focused, $15/$60",
      "bestFor": "Advanced reasoning, Mathematical problems",
      "optimalTeamExamples": "Advanced reasoning teams",
      "creativeScore": 6,
      "deductiveScore": 9.5,
      "specialPropertiesNotes": "Reasoning-focused model, $15/$60, Premium reasoning",
      "api_id": "openai/o1",
      "slug": "o1",
      "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.",
      "pricing": {
        "prompt": 15000000,
        "completion": 60000000,
        "tier": 3
      },
      "context_length": 200000,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "73",
      "vendor": "OpenAI",
      "modelFamily": "o",
      "modelName": "o1 Mini",
      "parametersB": "~1.3 (conflicting sources)",
      "contextK": "128",
      "personalityTraits": "Mod Openness (STEM-focused)",
      "analyticalTraits": "86th percentile Codeforces, 80% cheaper than o1-preview, STEM reasoning",
      "bestFor": "Cost-effective STEM reasoning",
      "optimalTeamExamples": "Budget STEM reasoning",
      "creativeScore": 5.5,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "$1.10/$4.40, 80% cheaper, STEM-optimized, Weaker non-STEM",
      "api_id": "openai/o1",
      "slug": "o1",
      "description": "The latest and strongest model family from OpenAI, o1 is designed to spend more time thinking before responding.",
      "pricing": {
        "prompt": 15000000,
        "completion": 60000000,
        "tier": 3
      },
      "context_length": 200000,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "72",
      "vendor": "OpenAI",
      "modelFamily": "o",
      "modelName": "o3 Mini",
      "parametersB": "Unknown",
      "contextK": "128",
      "personalityTraits": "Mod Openness",
      "analyticalTraits": "Latest mini reasoning, 92.7% AIME",
      "bestFor": "Latest compact reasoning",
      "optimalTeamExamples": "Latest mini reasoning teams",
      "creativeScore": 5.5,
      "deductiveScore": 9,
      "specialPropertiesNotes": "Latest mini reasoning, 92.7% AIME 2024",
      "api_id": "openai/o3-mini",
      "slug": "o3-mini",
      "description": "OpenAI o3-mini is a cost-efficient language model optimized for STEM reasoning tasks, particularly excelling in science, mathematics, and coding.\n\nThis model supports the `reasoning_effort` parameter, which can be set to \"high\", \"medium\", or \"low\" to control the thinking time of the model.",
      "pricing": {
        "prompt": 1100000,
        "completion": 4400000,
        "tier": 2
      },
      "context_length": 200000,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "134",
      "vendor": "Prime Intellect",
      "modelFamily": "INTELLECT",
      "modelName": "INTELLECT-3",
      "parametersB": "106 (12 active)",
      "contextK": 128,
      "personalityTraits": "Mod Conscientiousness",
      "analyticalTraits": "MoE trained via decentralized compute",
      "bestFor": "Decentralized training applications",
      "optimalTeamExamples": "Decentralized teams",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "MoE 106B/12B active, Decentralized compute training",
      "api_id": "prime-intellect/intellect-3",
      "slug": "intellect-3",
      "description": "INTELLECT-3 is a 106B-parameter Mixture-of-Experts model (12B active) post-trained from GLM-4.5-Air-Base using supervised fine-tuning (SFT) followed by large-scale reinforcement learning (RL).",
      "pricing": {
        "prompt": 200000,
        "completion": 1100000,
        "tier": 2
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "181",
      "vendor": "Qwen",
      "modelFamily": "QwQ",
      "modelName": "QwQ 32B Preview",
      "parametersB": "32",
      "contextK": "128",
      "personalityTraits": "High Openness (reasoning-focused)",
      "analyticalTraits": "Reasoning-focused preview",
      "bestFor": "Reasoning at 32B",
      "optimalTeamExamples": "Reasoning preview teams",
      "creativeScore": 5.5,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "32B reasoning preview",
      "api_id": "qwen/qwq-32b",
      "slug": "qwq-32b",
      "description": "QwQ is the reasoning model of the Qwen series.",
      "pricing": {
        "prompt": 150000,
        "completion": 400000,
        "tier": 1
      },
      "context_length": 32768,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "183",
      "vendor": "Qwen",
      "modelFamily": "Qwen 2.5",
      "modelName": "Qwen 2.5 Coder 32B Instruct",
      "parametersB": "32",
      "contextK": "131",
      "personalityTraits": "Mod Conscientiousness, Mod Openness",
      "analyticalTraits": "Coding specialist, Python focus",
      "bestFor": "Coding tasks, Python specialist",
      "optimalTeamExamples": "Coding specialist teams",
      "creativeScore": 6,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "32B coding specialist, Strong Python",
      "api_id": "qwen/qwen-2.5-coder-32b-instruct",
      "slug": "qwen-2.5-coder-32b-instruct",
      "description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen).",
      "pricing": {
        "prompt": 30000,
        "completion": 110000,
        "tier": 1
      },
      "context_length": 32768,
      "capabilities": []
    },
    {
      "id": "184",
      "vendor": "Qwen",
      "modelFamily": "Qwen 2.5",
      "modelName": "Qwen 2.5 72B Instruct",
      "parametersB": "72",
      "contextK": "131",
      "personalityTraits": "Balanced, High Conscientiousness",
      "analyticalTraits": "Native JSON, 29+ languages, MMLU 85+, HumanEval 85+, MATH 80+",
      "bestFor": "Multilingual coordination, Structured data, Knowledge anchor",
      "optimalTeamExamples": "Translator Corps, Board of Directors, International teams",
      "creativeScore": 6.5,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "72B flagship, 29+ languages, Native JSON, Cultural nuance, Open weights, Qwen License",
      "api_id": "qwen/qwen-2.5-72b-instruct",
      "slug": "qwen-2.5-72b-instruct",
      "description": "Qwen2.5 72B is the latest series of Qwen large language models.",
      "pricing": {
        "prompt": 120000,
        "completion": 390000,
        "tier": 1
      },
      "context_length": 32768,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "187",
      "vendor": "TheDrummer",
      "modelFamily": "Rocinante",
      "modelName": "Rocinante 12B",
      "parametersB": "12",
      "contextK": 32,
      "personalityTraits": "High Openness",
      "analyticalTraits": "Specialized creative",
      "bestFor": "Specialized creative tasks",
      "optimalTeamExamples": "Specialized creative teams",
      "creativeScore": 7.5,
      "deductiveScore": 6.5,
      "specialPropertiesNotes": "Specialized creative model",
      "api_id": "thedrummer/rocinante-12b",
      "slug": "rocinante-12b",
      "description": "Rocinante 12B is designed for engaging storytelling and rich prose.\n\nEarly testers have reported:\n- Expanded vocabulary with unique and expressive word choices\n- Enhanced creativity for vivid narratives\n- Adventure-filled and captivating stories",
      "pricing": {
        "prompt": 170000,
        "completion": 430000,
        "tier": 1
      },
      "context_length": 32768,
      "capabilities": [
        "tools",
        "tool_choice"
      ]
    },
    {
      "id": "5",
      "vendor": "Z.AI",
      "modelFamily": "GLM",
      "modelName": "GLM 4.7",
      "parametersB": "355 (32 active)",
      "contextK": "200",
      "personalityTraits": "High Conscientiousness, Mod Openness",
      "analyticalTraits": "Think-before-acting, Deep thinking, 73.8% SWE-bench, τ²-Bench 87.4%",
      "bestFor": "Technical creativity, Systematic innovation, Coding+creative, Agent frameworks",
      "optimalTeamExamples": "The Studio, TTRPG Orchestrator, Shadow Product Team",
      "creativeScore": 7,
      "deductiveScore": 8.5,
      "specialPropertiesNotes": "MoE 355B/32B active, MIT license, 200K context, 128K output, Enhanced programming",
      "api_id": "z-ai/glm-4.7",
      "slug": "glm-4.7",
      "description": "GLM-4.7 is Z.AI’s latest flagship model, featuring upgrades in two key areas: enhanced programming capabilities and more stable multi-step reasoning/execution.",
      "pricing": {
        "prompt": 160000,
        "completion": 800000,
        "tier": 1
      },
      "context_length": 202752,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "6",
      "vendor": "Z.AI",
      "modelFamily": "GLM",
      "modelName": "GLM 4.6V",
      "parametersB": "Unknown",
      "contextK": "200",
      "personalityTraits": "Mod Openness",
      "analyticalTraits": "Vision-language variant",
      "bestFor": "Vision-language tasks",
      "optimalTeamExamples": "Vision-language teams",
      "creativeScore": 7,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Vision-language variant",
      "api_id": "z-ai/glm-4.6v",
      "slug": "glm-4.6v",
      "description": "GLM-4.6V is a large multimodal model designed for high-fidelity visual understanding and long-context reasoning across images, documents, and mixed media.",
      "pricing": {
        "prompt": 300000,
        "completion": 900000,
        "tier": 2
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "7",
      "vendor": "Z.AI",
      "modelFamily": "GLM",
      "modelName": "GLM 4.6",
      "parametersB": "Unknown",
      "contextK": "200",
      "personalityTraits": "High Conscientiousness",
      "analyticalTraits": "Previous gen with 200K",
      "bestFor": "Previous gen tasks",
      "optimalTeamExamples": "Legacy GLM teams",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Previous generation, 200K context",
      "api_id": "z-ai/glm-4.6",
      "slug": "glm-4.6",
      "description": "Compared with GLM-4.5, this generation brings several key improvements:\n\nLonger context window: The context window has been expanded from 128K to 200K tokens, enabling the model to handle more complex agentic tasks.\nSuperior coding performance: The model achieves higher scores on code benchmarks and demonstrates better real-world performance in applications such as Claude Code、Cline、Roo Code and Kilo Code, including improvements in generating visually polished front-end pages.\nAdvanced reason...",
      "pricing": {
        "prompt": 350000,
        "completion": 1500000,
        "tier": 2
      },
      "context_length": 202752,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "8",
      "vendor": "Z.AI",
      "modelFamily": "GLM",
      "modelName": "GLM 4.6 (exacto)",
      "parametersB": "Unknown",
      "contextK": "200",
      "personalityTraits": "High Conscientiousness",
      "analyticalTraits": "Exacto variant",
      "bestFor": "Exacto-specific tasks",
      "optimalTeamExamples": "Exacto teams",
      "creativeScore": 6.5,
      "deductiveScore": 8,
      "specialPropertiesNotes": "Exacto variant",
      "api_id": "z-ai/glm-4.6:exacto",
      "slug": "glm-4.6:exacto",
      "description": "Compared with GLM-4.5, this generation brings several key improvements:\n\nLonger context window: The context window has been expanded from 128K to 200K tokens, enabling the model to handle more complex agentic tasks.\nSuperior coding performance: The model achieves higher scores on code benchmarks and demonstrates better real-world performance in applications such as Claude Code、Cline、Roo Code and Kilo Code, including improvements in generating visually polished front-end pages.\nAdvanced reason...",
      "pricing": {
        "prompt": 440000,
        "completion": 1760000,
        "tier": 2
      },
      "context_length": 204800,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "9",
      "vendor": "Z.AI",
      "modelFamily": "GLM",
      "modelName": "GLM 4.5V",
      "parametersB": "Unknown",
      "contextK": 64,
      "personalityTraits": "Mod Openness",
      "analyticalTraits": "Vision-language foundation",
      "bestFor": "Vision-language foundation",
      "optimalTeamExamples": "Vision foundation teams",
      "creativeScore": 7,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Vision-language foundation",
      "api_id": "z-ai/glm-4.5v",
      "slug": "glm-4.5v",
      "description": "GLM-4.5V is a vision-language foundation model for multimodal agent applications.",
      "pricing": {
        "prompt": 600000,
        "completion": 1800000,
        "tier": 2
      },
      "context_length": 65536,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "10",
      "vendor": "Z.AI",
      "modelFamily": "GLM",
      "modelName": "GLM 4.5",
      "parametersB": "Unknown",
      "contextK": 128,
      "personalityTraits": "Mod Conscientiousness",
      "analyticalTraits": "Agent-focused foundation",
      "bestFor": "Agent applications",
      "optimalTeamExamples": "Agent teams",
      "creativeScore": 6.5,
      "deductiveScore": 7.5,
      "specialPropertiesNotes": "Agent-focused foundation",
      "api_id": "z-ai/glm-4.5",
      "slug": "glm-4.5",
      "description": "GLM-4.5 is our latest flagship foundation model, purpose-built for agent-based applications.",
      "pricing": {
        "prompt": 350000,
        "completion": 1550000,
        "tier": 2
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    },
    {
      "id": "11",
      "vendor": "Z.AI",
      "modelFamily": "GLM",
      "modelName": "GLM 4.5 Air",
      "parametersB": "Unknown",
      "contextK": 128,
      "personalityTraits": "Mod Conscientiousness",
      "analyticalTraits": "Lightweight agent-centric",
      "bestFor": "Lightweight agent tasks",
      "optimalTeamExamples": "Lightweight agent teams",
      "creativeScore": 6,
      "deductiveScore": 7,
      "specialPropertiesNotes": "Lightweight agent-centric",
      "api_id": "z-ai/glm-4.5-air",
      "slug": "glm-4.5-air",
      "description": "GLM-4.5-Air is the lightweight variant of our latest flagship model family, also purpose-built for agent-centric applications.",
      "pricing": {
        "prompt": 50000,
        "completion": 220000,
        "tier": 1
      },
      "context_length": 131072,
      "capabilities": [
        "tools",
        "tool_choice",
        "reasoning"
      ]
    }
  ]
}